[UserSettings]
repo_url = https://github.com/TensorMouse/kohya-trainer
branch = one-cell-script
install_xformers = True
verbose = False

[DownloadModels]
model_url = https://huggingface.co/SG161222/Realistic_Vision_V2.0/resolve/main/Realistic_Vision_V2.0-fp16-no-ema.safetensors
vae_url = https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt
;Models = {
;    "Animefull-final-pruned": "https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt",
;    "Anything-v3-1": "https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors",
;    "AnyLoRA": "https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors",
;    "AnimePastelDream": "https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors",
;    "Chillout-mix": "https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors",
;    "OpenJourney-v4": "https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt",
;    "Stable-Diffusion-v1-5": "https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors",
;}

;v2_models = {
;    "stable-diffusion-2-1-base": "https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors",
;    "stable-diffusion-2-1-768v": "https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors",
;    "plat-diffusion-v1-3-1": "https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors",
;    "replicant-v1": "https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors",
;    "illuminati-diffusion-v1-0": "https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors",
;    "illuminati-diffusion-v1-1": "https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors",
;    "waifu-diffusion-1-4-anime-e2": "https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt",
;    "waifu-diffusion-1-5-e2": "https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors",
;    "waifu-diffusion-1-5-e2-aesthetic": "https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors",
;}

[ImagePreprocessing]
convert = True 
;Convert to RGB with white background
random_color = False
;Use random color background instead of white
recursive = False
;Process subfolders as well

[Captioning]
captioning = BLIP
batch_size = 8
max_data_loader_n_workers = 2
beam_search = True
min_length = 5
max_length = 75
recursive = False
verbose_logging = True
model = SmilingWolf/wd-v1-4-convnextv2-tagger-v2
undesired_tags = 
general_threshold = 0.35
character_threshold = 0.35
caption_extension = .caption

[CustomCaptionTag]
extension = .caption
custom_tag = my_custom_tag
keywords = a man, a woman, a person
sub_folder = None
append = False
prefix_tag = False
remove_tag = False
recursive = False

[model_arguments]
v2 = False
v_parameterization = False

[optimizer_arguments]
optimizer_type = AdamW8bit
learning_rate = 2e-6
max_grad_norm = 1.0
lr_scheduler = cosine_with_restarts
lr_warmup_steps = 0
lr_scheduler_num_cycles = 0

[dataset_arguments]
cache_latents = True
debug_dataset = False
vae_batch_size = 1

[dataset]
resolution = 512
min_bucket_reso = 256
max_bucket_reso = 1024
caption_dropout_rate = 0
caption_tag_dropout_rate = 0
caption_dropout_every_n_epochs = 0
flip_aug = False
color_aug = False

[dataset_subset]
class_tokens = myClassToken
num_repeats = 10

[general]
enable_bucket = True
caption_extension = .caption
shuffle_caption = True
keep_tokens = 0
bucket_reso_steps = 64
bucket_no_upscale = False

[training_arguments]
output_dir = /home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/output
output_name = myTrainedModel
save_precision = fp16
save_every_n_epochs = 1
save_checkpoint_local = False
save_state = False
train_batch_size = 4
max_token_length = 225
mem_eff_attn = False
xformers = True
max_train_steps = 600
max_data_loader_n_workers = 8
persistent_data_loader_workers = True
gradient_checkpointing = False
gradient_accumulation_steps = 1
mixed_precision = fp16
clip_skip = 1
logging_dir = /home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/logs
log_prefix = myTrainedModel

[sample_prompt_arguments]
samples_per_prompt = 1
sample_every_n_steps = 999999
sample_every_n_epochs = 1
sample_sampler = euler_a

[dreambooth_arguments]
prior_loss_weight = 1.0

[saving_arguments]
save_model_as = ckpt

[huggingface_arguments]
huggingface_path_in_repo = myModel
async_upload = False
huggingface_repo_id = xxthekingxx/myTrainedModel