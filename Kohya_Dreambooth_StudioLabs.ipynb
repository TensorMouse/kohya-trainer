{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85734b6d-e63b-455f-8d96-40c97b1b1aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import configparser\n",
    "import random\n",
    "import concurrent.futures\n",
    "import time\n",
    "from library.studiolabs_utils import (\n",
    "    clone_or_update_repo,\n",
    "    install_dependencies,\n",
    "    create_dirs,\n",
    "    download_model,\n",
    "    get_config_from_folder,\n",
    "    preprocess_folder,\n",
    "    update_model_paths,\n",
    "    get_config_file_paths,\n",
    "    get_config_dict_from_ini,\n",
    "    get_train_args\n",
    ")\n",
    "\n",
    "\n",
    "print('1.0 DEFINE DIRECTORIES')\n",
    "dirs = create_dirs()\n",
    "print('2.0 CLONE REPO AND INSTALL DIRECTORIES')\n",
    "# Read the config.ini file\n",
    "default_config = configparser.ConfigParser()\n",
    "default_config.read(dirs['default_config'])\n",
    "\n",
    "print(dirs['accelerate_config'])\n",
    "clone_or_update_repo(\n",
    "    url=default_config.get('UserSettings', 'repo_url'),\n",
    "    save_directory=dirs['root_dir'],\n",
    "    branch = default_config.get('UserSettings', 'branch')\n",
    "    )\n",
    "\n",
    "\n",
    "install_dependencies(\n",
    "    dirs,\n",
    "    verbose=default_config.getboolean('UserSettings', 'verbose'), \n",
    "    install_xformers=default_config.getboolean('UserSettings', 'install_xformers')\n",
    "    )\n",
    "\n",
    "command = \"pip cache purge\"\n",
    "subprocess.run(command, shell=True)\n",
    "command = \"accelerate config default\"\n",
    "subprocess.run(command, shell=True)\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "import matplotlib.font_manager as fm\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
    "\n",
    "def authenticate(write_token):\n",
    "    login(write_token, add_to_git_credential=True)\n",
    "    api = HfApi()\n",
    "    return api.whoami(write_token), api\n",
    "\n",
    "\n",
    "def create_repo(api, user, orgs_name, repo_name, repo_type, make_private=False):\n",
    "    global model_repo\n",
    "    global datasets_repo\n",
    "    \n",
    "    if orgs_name == \"\":\n",
    "        repo_id = user[\"name\"] + \"/\" + repo_name.strip()\n",
    "    else:\n",
    "        repo_id = orgs_name + \"/\" + repo_name.strip()\n",
    "\n",
    "    try:\n",
    "        validate_repo_id(repo_id)\n",
    "        api.create_repo(repo_id=repo_id, repo_type=repo_type, private=make_private)\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' didn't exist, creating repo\")\n",
    "    except HfHubHTTPError as e:\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' exists, skipping create repo\")\n",
    "    \n",
    "    if repo_type == \"model\":\n",
    "        model_repo = repo_id\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
    "    else:\n",
    "        datasets_repo = repo_id\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/datasets/{repo_id}\\n\")\n",
    "\n",
    "user, api = authenticate(write_token)\n",
    "\n",
    "# Get the parameter values from the config file\n",
    "model_url = default_config.get('DownloadModels', 'model_url')\n",
    "vae_url = default_config.get('DownloadModels', 'vae_url')\n",
    "\n",
    "\n",
    "# Download the model file if it doesn't exist\n",
    "download_model(model_url, dirs['pretrained_dir'])\n",
    "download_model(vae_url, dirs['vae_dir'])\n",
    "    \n",
    "print('4.1 DATA CLEANING + BLIP Captioning + Custom Caption/Tag')\n",
    "# Use BLIP for general images\n",
    "# Use Waifu for anime/manga images\n",
    "# Specified in the config file\n",
    "\n",
    "skip_cleaning_captioning=False\n",
    "\n",
    "subfolders = [\n",
    "    os.path.join(dirs['train_data_dir'], f)\n",
    "    for f in os.listdir(dirs['train_data_dir'])\n",
    "    if os.path.isdir(os.path.join(dirs['train_data_dir'], f)) \n",
    "    and not f.startswith('.')\n",
    "]\n",
    "\n",
    "\n",
    "for folder in subfolders:\n",
    "    if not skip_cleaning_captioning:\n",
    "        preprocess_folder(folder, dirs, default_config)\n",
    "        \n",
    "        #@title ## 5 Start Training\n",
    "\n",
    "    sample_prompt, config_file = get_config_file_paths(folder, dirs)\n",
    "    \n",
    "    if config_file is None:\n",
    "        train_config = default_config\n",
    "    else:\n",
    "        train_config = configparser.ConfigParser()\n",
    "        train_config.read(config_file)\n",
    "\n",
    "\n",
    "    # Create an empty dictionary\n",
    "    token_dictionary = get_config_dict_from_ini(os.path.join(dirs['default_configs_dir'],'my_tokens.ini'))\n",
    "\n",
    "\n",
    "    accelerate_conf = {\n",
    "        \"config_file\" : dirs['accelerate_config'],\n",
    "        \"num_cpu_threads_per_process\" : 1,\n",
    "    }\n",
    "\n",
    "    train_confing2 = {\n",
    "        \"train_data_dir\" : folder,\n",
    "        \"huggingface_token\" : token_dictionary['huggingface_token'],\n",
    "        \"sample_prompts\" : sample_prompt\n",
    "    }\n",
    "    \n",
    "    train_config_full = {}\n",
    "    train_config_full.update(dict(train_config.items('model_arguments')))\n",
    "    train_config_full.update(dict(train_config.items('optimizer_arguments')))\n",
    "    train_config_full.update(dict(train_config.items('dataset_arguments')))\n",
    "    train_config_full.update(dict(train_config.items('dataset')))\n",
    "    train_config_full.update(dict(train_config.items('dataset_subset')))\n",
    "    train_config_full.update(dict(train_config.items('general')))\n",
    "    train_config_full.update(dict(train_config.items('training_arguments')))\n",
    "    train_config_full.update(dict(train_config.items('sample_prompt_arguments')))\n",
    "    train_config_full.update(dict(train_config.items('sample_prompt_arguments')))\n",
    "    train_config_full.update(dict(train_config.items('saving_arguments')))\n",
    "    train_config_full.update(dict(train_config.items('huggingface_arguments')))\n",
    "    train_config_full.update(token_dictionary)\n",
    "    train_config_full.update(train_confing2)\n",
    "    \n",
    "\n",
    "    accelerate_args = get_train_args(accelerate_conf)\n",
    "    train_args = get_train_args(train_config_full)\n",
    "    print('TRAIN ARGS: ',train_args)\n",
    "    final_args = f\"accelerate launch {accelerate_args} train_db.py {train_args}\"\n",
    "    print(final_args)\n",
    "    subprocess.run(final_args, shell=True, check=True)\n",
    "    trained_model_name=train_config.get('training_arguments', 'output_name')\n",
    "    output_directory=os.path.join(dirs['dreambooth_output_dir'],'sample',trained_model_name)\n",
    "    # Fetch image files from the directory\n",
    "    image_locations = fetch_image_locations(output_directory)\n",
    "    prompts = sorted(list(set([img_name.split('_')[1] for img_name in image_locations])))\n",
    "    epochs = sorted(list(set([img_name.split('_')[2][1:] for img_name in image_locations])))\n",
    "    font, fontsize = get_font()\n",
    "    \n",
    "    grid_name=trained_model_name+'_grid.png'\n",
    "    grid_save_dir=os.path.join(dirs['dreambooth_sample_dir'],grid_name)\n",
    "    max_image_width = 0\n",
    "    max_image_height = 0\n",
    "\n",
    "    # Find the maximum width and height among all images\n",
    "    for image_file in image_locations:\n",
    "        image_path = os.path.join(output_directory, image_file)\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        max_image_width = max(max_image_width, width)\n",
    "        max_image_height = max(max_image_height, height)\n",
    "\n",
    "    canvas_width = ((max_image_width + padding) * len(epochs)) + padding + left_space\n",
    "    canvas_height = ((max_image_height + padding) * len(prompts)) + padding + top_space\n",
    "    canvas = Image.new('RGB', (canvas_width, canvas_height), 'white')\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "    # Iterate over the image files and place them in the grid\n",
    "    for i,epoch in enumerate(epochs):\n",
    "        epoch_x = ((max_image_width + padding) * i) + padding + left_space \n",
    "        epoch_y = text_offset \n",
    "        draw.text((epoch_x, epoch_y), f'Epoch: {epoch}', fill='black', font=font)\n",
    "        for k,prompt in enumerate(prompts):\n",
    "        \n",
    "            text=prompt\n",
    "            #Shorten the text if it exceeds 50 characters\n",
    "            if len(text) > 200:\n",
    "                text = text[:200] + '...'\n",
    "\n",
    "            # Wrap the text to fit within the limit\n",
    "            wrapped_text = textwrap.wrap(text, width=int(text_width_limit / fontsize))\n",
    "\n",
    "            # Calculate the total height required for the wrapped text\n",
    "            total_text_height = len(wrapped_text) * fontsize\n",
    "\n",
    "            # Calculate the starting position to center the text vertically\n",
    "            y_start = top_space + padding + k * (padding + max_image_height)\n",
    "            x = text_offset * 4\n",
    "\n",
    "            # Draw the wrapped text\n",
    "            for line in wrapped_text:\n",
    "                text_bbox = draw.textbbox((0, y_start), line, font=font)\n",
    "                text_width = text_bbox[2] - text_bbox[0]\n",
    "                text_height = text_bbox[3] - text_bbox[1]\n",
    "                draw.text((x, y_start), line, font=font, fill='black')\n",
    "                y_start += fontsize\n",
    "        \n",
    "            for img_name in image_locations:\n",
    "                if epoch == img_name.split('_')[2][1:] and prompt == img_name.split('_')[1]:\n",
    "                    image_path = os.path.join(output_directory, img_name)\n",
    "                    img = Image.open(image_path)\n",
    "\n",
    "                    # Calculate the position of the image in the grid\n",
    "                    x = (max_image_width + padding) * i + padding + left_space\n",
    "                    y = top_space + (max_image_height + padding) * k + padding\n",
    "\n",
    "                    # Paste the image onto the canvas\n",
    "                    canvas.paste(img, (x, y))\n",
    "\n",
    "    # Save the final image grid\n",
    "    canvas.save(grid_save_dir)\n",
    "    print('Saved')\n",
    "    # @markdown Login to Huggingface Hub\n",
    "    # @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
    "    write_token = token_dictionary['huggingface_token']\n",
    "    # @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
    "    # @markdown If your model/dataset repo does not exist, it will automatically create it.\n",
    "    make_private = True\n",
    "    user, api = authenticate(write_token)\n",
    "          \n",
    "    # @markdown This will be uploaded to model repo\n",
    "    #model_path = os.path.join(dreambooth_output_dir,\"Hen1.ckpt\")  # @param {type :\"string\"}\n",
    "    path_in_repo = \"\"  # @param {type :\"string\"}\n",
    "    # @markdown Now you can save your config file for future use\n",
    "    # @markdown Other Information\n",
    "    commit_message = \"uploading model\"  # @param {type :\"string\"}\n",
    "\n",
    "    if not commit_message:\n",
    "        commit_message = \"feat: upload checkpoint\"\n",
    "\n",
    "    for f in os.listdir(dirs['dreambooth_sample_dir']):\n",
    "        if not f.startswith('.'):\n",
    "            create_repo(api, user, orgs_name, f, \"model\", make_private)\n",
    "\n",
    "    print(\"uploading to: \",user[\"name\"] + \"/\" + trained_model_name)\n",
    "    \n",
    "    if config_file is None:\n",
    "        upload_config=dirs['default_config']\n",
    "    else:\n",
    "        upload_config=config_file\n",
    "        \n",
    "    print(\"uploading config files\")\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=upload_config)\n",
    "        path_in_repo=\"config/config.ini\",\n",
    "        repo_id=user[\"name\"] + \"/\" + trained_model_name,\n",
    "        repo_type=None,\n",
    "    )\n",
    "    \n",
    "    print(\"uploading sample prompt\")\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=sample_prompt)\n",
    "        path_in_repo=\"config/sample_prompt.txt\",\n",
    "        repo_id=user[\"name\"] + \"/\" + trained_model_name,\n",
    "        repo_type=None,\n",
    "    )\n",
    "\n",
    "    print(\"uploading sample images\")\n",
    "    api.upload_folder(\n",
    "        folder_path=os.path.join(dirs['dreambooth_sample_dir'], trained_model_name)\n",
    "        repo_id=user[\"name\"] + \"/\" + trained_model_name,\n",
    "        repo_type=None,\n",
    "        path_in_repo=\"samples\",\n",
    "    )\n",
    "    print(\"uploading sample image grid\")\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=grid_save_dir)\n",
    "        path_in_repo=grid_name,\n",
    "        repo_id=user[\"name\"] + \"/\" + trained_model_name,\n",
    "        repo_type=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937f88d-819a-4e35-bc36-353198d18048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ## 6.2. Inference\n",
    "v2 = False  # @param {type:\"boolean\"}\n",
    "v_parameterization = False  # @param {type:\"boolean\"}\n",
    "prompt = \"RAW photo, mirox in a fancy suit, fashion magazine photoshoot, full body shot, high detailed skin, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3\"  # @param {type: \"string\"}\n",
    "negative = \"(weird eyes, disfigured eyes, looking different direction:1.3), cgi, 3d, render, mutated hands, mutated fingers, deformed, distorted, disfigured, poorly drawn, bad anatomy, bad quality, worst quality\"  # @param {type: \"string\"}\n",
    "model = os.path.join(dreambooth_output_dir,'Miroslav7.ckpt')  # @param {type: \"string\"}\n",
    "vae = os.path.join(vae_dir,'vae-ft-mse-840000-ema-pruned.ckpt')  # @param {type: \"string\"}\n",
    "outdir = inference_dir  # @param {type: \"string\"}\n",
    "scale = 7  # @param {type: \"slider\", min: 1, max: 40}\n",
    "sampler = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
    "steps = 35  # @param {type: \"slider\", min: 1, max: 100}\n",
    "precision = \"fp16\"  # @param [\"fp16\", \"bf16\"] {allow-input: false}\n",
    "width = 512  # @param {type: \"integer\"}\n",
    "height = 768  # @param {type: \"integer\"}\n",
    "images_per_prompt = 12  # @param {type: \"integer\"}\n",
    "batch_size = 1  # @param {type: \"integer\"}\n",
    "clip_skip = 1  # @param {type: \"slider\", min: 1, max: 40}\n",
    "seed = -1  # @param {type: \"integer\"}\n",
    "\n",
    "final_prompt = f\"{prompt} --n {negative}\"\n",
    "\n",
    "config = {\n",
    "    \"v2\": v2,\n",
    "    \"v_parameterization\": v_parameterization,\n",
    "    \"ckpt\": model,\n",
    "    \"outdir\": outdir,\n",
    "    \"xformers\": True,\n",
    "    \"vae\": vae if vae else None,\n",
    "    \"fp16\": True,\n",
    "    \"W\": width,\n",
    "    \"H\": height,\n",
    "    \"seed\": seed if seed > 0 else None,\n",
    "    \"scale\": scale,\n",
    "    \"sampler\": sampler,\n",
    "    \"steps\": steps,\n",
    "    \"max_embeddings_multiples\": 3,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"images_per_prompt\": images_per_prompt,\n",
    "    \"clip_skip\": clip_skip if not v2 else None,\n",
    "    \"prompt\": final_prompt,\n",
    "}\n",
    "\n",
    "args = \"\"\n",
    "for k, v in config.items():\n",
    "    if isinstance(v, str):\n",
    "        args += f'--{k}=\"{v}\" '\n",
    "    if isinstance(v, bool) and v:\n",
    "        args += f\"--{k} \"\n",
    "    if isinstance(v, float) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "    if isinstance(v, int) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "\n",
    "final_args = f\"python gen_img_diffusers.py {args}\"\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "!{final_args}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
