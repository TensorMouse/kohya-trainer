{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2596e95c-f99f-4473-8f02-b3970387366f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b5fc8c7b504af6b249d95a291bcb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='https://github.com/TensorMouse/kohya-trainer', description='Repository URL:', layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.0 DEFINE DIRECTORIES\n",
    "\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# root_dir\n",
    "root_dir                = \"/home/studio-lab-user/sagemaker-studiolab-notebooks\"\n",
    "deps_dir                = os.path.join(root_dir, \"deps\")\n",
    "repo_dir                = os.path.join(root_dir, \"kohya-trainer\")\n",
    "pretrained_dir          = os.path.join(root_dir, \"pretrained_model\")\n",
    "vae_dir                 = os.path.join(root_dir, \"vae\")\n",
    "\n",
    "dreambooth_training_dir = os.path.join(root_dir, \"dreambooth\")\n",
    "dreambooth_config_dir   = os.path.join(dreambooth_training_dir, \"config\")\n",
    "dreambooth_output_dir   = os.path.join(dreambooth_training_dir, \"output\") \n",
    "dreambooth_sample_dir   = os.path.join(dreambooth_output_dir, \"sample\")\n",
    "dreambooth_logging_dir  = os.path.join(dreambooth_training_dir, \"logs\")\n",
    "\n",
    "inference_dir           = os.path.join(root_dir, \"txt2img\")\n",
    "\n",
    "train_data_dir          = os.path.join(root_dir, \"train_data\")  \n",
    "reg_data_dir            = os.path.join(root_dir, \"reg_data\")  \n",
    "\n",
    "# repo_dir\n",
    "accelerate_config       = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
    "tools_dir               = os.path.join(repo_dir, \"tools\")\n",
    "finetune_dir            = os.path.join(repo_dir, \"finetune\")\n",
    "\n",
    "os.chdir(root_dir)\n",
    "\n",
    "for dir in [\n",
    "    deps_dir,\n",
    "    dreambooth_training_dir,\n",
    "    dreambooth_config_dir,\n",
    "    dreambooth_output_dir,\n",
    "    pretrained_dir,\n",
    "    dreambooth_sample_dir,\n",
    "    inference_dir,\n",
    "    vae_dir, \n",
    "    train_data_dir, \n",
    "    reg_data_dir\n",
    "]:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# User settings\n",
    "repo_url          = widgets.Text(\n",
    "    value         = \"https://github.com/TensorMouse/kohya-trainer\",\n",
    "    description   = \"Repository URL:\",\n",
    "    style         = {\"description_width\": \"initial\"},\n",
    "    layout        = widgets.Layout(width='50%')\n",
    ")\n",
    "branch            = widgets.Text(\n",
    "    value         = \"\",\n",
    "    description   = \"Branch:\",\n",
    "    style         = {\"description_width\": \"initial\"},\n",
    "    layout        = widgets.Layout(width='50%')\n",
    ")\n",
    "tooltip_branch    = widgets.HTML(\n",
    "    value         = '<span style=\"color: blue;\">Leave the box empty to use the default repository.</span>'\n",
    ")\n",
    "install_xformers  = widgets.Checkbox(\n",
    "    value         = True,\n",
    "    description   = \"Install xformers\"\n",
    ")\n",
    "verbose           = widgets.Checkbox(\n",
    "    value         = False,\n",
    "    description   = \"Verbose\"\n",
    ")\n",
    "\n",
    "box = widgets.VBox([\n",
    "    repo_url,\n",
    "    widgets.VBox([tooltip_branch, branch]),\n",
    "    install_xformers,\n",
    "    verbose\n",
    "])\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d40c52-d59d-4f43-8868-daf1bf92a7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer'...\n",
      "remote: Enumerating objects: 1988, done.\u001b[K\n",
      "remote: Counting objects: 100% (656/656), done.\u001b[K\n",
      "remote: Compressing objects: 100% (188/188), done.\u001b[K\n",
      "remote: Total 1988 (delta 528), reused 514 (delta 468), pack-reused 1332\u001b[K\n",
      "Receiving objects: 100% (1988/1988), 3.66 MiB | 27.79 MiB/s, done.\n",
      "Resolving deltas: 100% (1283/1283), done.\n",
      "Installation can take multiple minutes, enable \"Verbose\" to see progress\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 14:06:31.764987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 32\n"
     ]
    }
   ],
   "source": [
    "# @title ## 1.1.0 CLONE REPO\n",
    "# @markdown Clone Kohya Trainer from GitHub and check for updates. Use textbox below if you want to checkout other branch or old commit. Leave it empty to stay the HEAD on main.  This will also install the required libraries.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from subprocess import getoutput\n",
    "\n",
    "def clone_repo(url,repo_dir):\n",
    "    if not os.path.exists(repo_dir):\n",
    "        os.chdir(root_dir)\n",
    "        !git clone {url} {repo_dir}\n",
    "    else:\n",
    "        print(\"Repo already exists\")\n",
    "        #os.chdir(repo_dir)\n",
    "        #!git pull origin {branch.value} if branch.value else !git pull\n",
    "        \n",
    "def install_dependencies():\n",
    "    print('Installation can take multiple minutes, enable \"Verbose\" to see progress')\n",
    "    s = getoutput('nvidia-smi')\n",
    "\n",
    "    if 'T4' in s:\n",
    "        !sed -i \"s@cpu@cuda@\" library/model_util.py\n",
    "\n",
    "    !pip install {'-q' if not verbose.value else ''} --upgrade -r requirements.txt\n",
    "    !pip install {'-q' if not verbose.value else ''} torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
    "    !conda install -c conda-forge glib --yes\n",
    "    \n",
    "    if install_xformers.value:\n",
    "        !pip install {'-q' if not verbose.value else ''} xformers==0.0.19 triton==2.0.0 -U\n",
    "        \n",
    "    from accelerate.utils import write_basic_config\n",
    "\n",
    "    if not os.path.exists(accelerate_config):\n",
    "        write_basic_config(save_location=accelerate_config)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    clone_repo(repo_url.value, repo_dir)\n",
    "    os.chdir(repo_dir)\n",
    "    install_dependencies()\n",
    "\n",
    "main()\n",
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e39878-0db3-4cc4-bdc9-d602f0955f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78f6c3ad55a486a9cc4af1090f3d337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<span style=\"color: blue;\">Leave boxes empty to not install a model. Run this box a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title ## 2.1. Download Available Model\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "\n",
    "os.chdir(root_dir)\n",
    "\n",
    "tooltip_model = widgets.HTML(value='<span style=\"color: blue;\">Leave boxes empty to not install a model. Run this box again, to lock in choices.</span>') \n",
    "\n",
    "models = {\n",
    "    \"Animefull-final-pruned\": \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
    "    \"Anything-v3-1\": \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
    "    \"AnyLoRA\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors\",\n",
    "    \"AnimePastelDream\": \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
    "    \"Chillout-mix\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
    "    \"OpenJourney-v4\": \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
    "    \"Stable-Diffusion-v1-5\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\",\n",
    "}\n",
    "\n",
    "v2_models = {\n",
    "    \"stable-diffusion-2-1-base\": \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\",\n",
    "    \"stable-diffusion-2-1-768v\": \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\n",
    "    \"plat-diffusion-v1-3-1\": \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\",\n",
    "    \"replicant-v1\": \"https://huggingface.co/gsdf/Replicant-V1.0/resolve/main/Replicant-V1.0.safetensors\",\n",
    "    \"illuminati-diffusion-v1-0\": \"https://huggingface.co/IlluminatiAI/Illuminati_Diffusion_v1.0/resolve/main/illuminati_diffusion_v1.0.safetensors\",\n",
    "    \"illuminati-diffusion-v1-1\": \"https://huggingface.co/4eJIoBek/Illuminati-Diffusion-v1-1/resolve/main/illuminatiDiffusionV1_v11.safetensors\",\n",
    "    \"waifu-diffusion-1-4-anime-e2\": \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\",\n",
    "    \"waifu-diffusion-1-5-e2\": \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-fp32.safetensors\",\n",
    "    \"waifu-diffusion-1-5-e2-aesthetic\": \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp32.safetensors\",\n",
    "}\n",
    "\n",
    "vaes = {\n",
    "    \"none\": \"\",\n",
    "    \"anime.vae.pt\": \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\",\n",
    "    \"waifudiffusion.vae.pt\": \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\",\n",
    "    \"stablediffusion.vae.pt\": \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\",\n",
    "}\n",
    "\n",
    "# Create the dropdown selector for model_name\n",
    "model_name = widgets.Dropdown(\n",
    "    options=[\"\"] + list(models.keys()),\n",
    "    value=\"Stable-Diffusion-v1-5\",\n",
    "    description=\"SD1.x model:\"\n",
    ")\n",
    "\n",
    "# Create the dropdown selector for v2_model_name\n",
    "v2_model_name = widgets.Dropdown(\n",
    "    options=[\"\"] + list(v2_models.keys()),\n",
    "    value=\"\",\n",
    "    description=\"SD2.x model:\"\n",
    ")\n",
    "\n",
    "# Create the text input for custom model URL\n",
    "custom_model_url_text = widgets.Text(\n",
    "    placeholder=\"Paste custom model URL\",\n",
    "    description=\"Custom Model:\",\n",
    ")\n",
    "\n",
    "vaes_name = widgets.Dropdown(\n",
    "    options=[\"\"] + list(vaes.keys()),\n",
    "    value=\"stablediffusion.vae.pt\",\n",
    "    description=\"Vae model:\"\n",
    ")\n",
    "\n",
    "vaes_custom = widgets.Text(\n",
    "    placeholder=\"Paste custom vaes URL\",\n",
    "    description=\"Custom Vae Model:\",\n",
    ")\n",
    "\n",
    "# Combine the dropdown selectors\n",
    "dropdown_box = widgets.VBox([tooltip_model, model_name, v2_model_name, custom_model_url_text, vaes_name, vaes_custom])\n",
    "dropdown_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e78ca8-54fb-4105-8193-f5bfafe68a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-02 12:39:28--  https://civitai.com/api/download/models/29460\n",
      "Resolving civitai.com (civitai.com)... 104.18.23.206, 104.18.22.206, 2606:4700::6812:17ce, ...\n",
      "Connecting to civitai.com (civitai.com)|104.18.23.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/26957/training-images/realisticVisionV20Fp16.Or1n.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22realisticVisionV20_v20NoVAE.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=2fea663d76bd24a496545da373d610fc/20230602/us-east-1/s3/aws4_request&X-Amz-Date=20230602T123928Z&X-Amz-SignedHeaders=host&X-Amz-Signature=8a277a7026b1feb9089c343b18cbce3bf61144fccb9bb61856eb6bb4dd6600f5 [following]\n",
      "--2023-06-02 12:39:28--  https://civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/26957/training-images/realisticVisionV20Fp16.Or1n.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22realisticVisionV20_v20NoVAE.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=2fea663d76bd24a496545da373d610fc/20230602/us-east-1/s3/aws4_request&X-Amz-Date=20230602T123928Z&X-Amz-SignedHeaders=host&X-Amz-Signature=8a277a7026b1feb9089c343b18cbce3bf61144fccb9bb61856eb6bb4dd6600f5\n",
      "Resolving civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 104.18.8.90, 104.18.9.90, 2606:4700::6812:95a, ...\n",
      "Connecting to civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod-2023-06-01.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|104.18.8.90|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2132650523 (2.0G) [application/octet-stream]\n",
      "Saving to: 'realisticVisionV20_v20NoVAE.safetensors'\n",
      "\n",
      "realisticVisionV20_ 100%[===================>]   1.99G  72.5MB/s    in 27s     \n",
      "\n",
      "2023-06-02 12:39:56 (74.3 MB/s) - 'realisticVisionV20_v20NoVAE.safetensors' saved [2132650523/2132650523]\n",
      "\n",
      "--2023-06-02 12:39:56--  https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\n",
      "Resolving huggingface.co (huggingface.co)... 108.156.184.45, 108.156.184.52, 108.156.184.118, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.156.184.45|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/c6a580b13a5bc05a5e16e4dbb80608ff2ec251a162311590c1f34c013d7f3dab?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.ckpt%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.ckpt%22%3B&Expires=1685964915&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VjL2VlL2VjZWVlMjZjNTgzNGQ4YTc1Y2YwNGVlYjE3ZGZjMDZkMWQ1ZmUxZDgwYzJmMTk1MjBiMTQ4YzExZTJlOThjNDUvYzZhNTgwYjEzYTViYzA1YTVlMTZlNGRiYjgwNjA4ZmYyZWMyNTFhMTYyMzExNTkwYzFmMzRjMDEzZDdmM2RhYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODU5NjQ5MTV9fX1dfQ__&Signature=n3azWg80hNzsMwfhV8n9MppO46YddgR6yWenCAg5l3eY9YGd07OkUUW4H2NLJYnatKi1FGJTG85fQ2XJ9WKCn4R16HP475jedhr1ufNVjADl54gBzmpy%7EMhaRIzZaOcgnhx%7EoXdGkujBF8X8CrCWXAP6Jg2ankTdpiSguyoX-oUWqHoCXBbs5zB1ur-%7EX-B5qRCoyJZXMyIFw3FmqVIZYRijy6FaH1MyLUVRYGjpaD1Gyq51YvFK-qHByT%7EZTAhtWyuRuR02qyxFSMRTaKjbc2NNhPi76AykCxHagmarulzwp2PL4ATUhMzuli2eqdN1cPYHNR4qP9SkYeROEfxKWg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-06-02 12:39:56--  https://cdn-lfs.huggingface.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/c6a580b13a5bc05a5e16e4dbb80608ff2ec251a162311590c1f34c013d7f3dab?response-content-disposition=attachment%3B+filename*%3DUTF-8''vae-ft-mse-840000-ema-pruned.ckpt%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.ckpt%22%3B&Expires=1685964915&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2VjL2VlL2VjZWVlMjZjNTgzNGQ4YTc1Y2YwNGVlYjE3ZGZjMDZkMWQ1ZmUxZDgwYzJmMTk1MjBiMTQ4YzExZTJlOThjNDUvYzZhNTgwYjEzYTViYzA1YTVlMTZlNGRiYjgwNjA4ZmYyZWMyNTFhMTYyMzExNTkwYzFmMzRjMDEzZDdmM2RhYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODU5NjQ5MTV9fX1dfQ__&Signature=n3azWg80hNzsMwfhV8n9MppO46YddgR6yWenCAg5l3eY9YGd07OkUUW4H2NLJYnatKi1FGJTG85fQ2XJ9WKCn4R16HP475jedhr1ufNVjADl54gBzmpy~MhaRIzZaOcgnhx~oXdGkujBF8X8CrCWXAP6Jg2ankTdpiSguyoX-oUWqHoCXBbs5zB1ur-~X-B5qRCoyJZXMyIFw3FmqVIZYRijy6FaH1MyLUVRYGjpaD1Gyq51YvFK-qHByT~ZTAhtWyuRuR02qyxFSMRTaKjbc2NNhPi76AykCxHagmarulzwp2PL4ATUhMzuli2eqdN1cPYHNR4qP9SkYeROEfxKWg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.156.184.106, 108.156.184.7, 108.156.184.64, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.156.184.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 334695179 (319M) [binary/octet-stream]\n",
      "Saving to: 'vae-ft-mse-840000-ema-pruned.ckpt'\n",
      "\n",
      "vae-ft-mse-840000-e 100%[===================>] 319.19M   220MB/s    in 1.5s    \n",
      "\n",
      "2023-06-02 12:39:58 (220 MB/s) - 'vae-ft-mse-840000-ema-pruned.ckpt' saved [334695179/334695179]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(pretrained_dir)\n",
    "\n",
    "if model_name.value:\n",
    "    model_url = models.get(model_name.value)\n",
    "    model_file = os.path.basename(model_url)\n",
    "    if not os.path.exists(os.path.join(pretrained_dir, model_file)):\n",
    "        !wget {model_url}\n",
    "    else:\n",
    "        print(f\"Model '{model_file}' already exists in the directory. Skipping download.\")\n",
    "\n",
    "if v2_model_name.value:\n",
    "    v2_model_url = v2_models.get(v2_model_name.value)\n",
    "    v2_model_file = os.path.basename(v2_model_url)\n",
    "    if not os.path.exists(os.path.join(pretrained_dir, v2_model_file)):\n",
    "        !wget {v2_model_url}\n",
    "    else:\n",
    "        print(f\"Model '{v2_model_file}' already exists in the directory. Skipping download.\")\n",
    "\n",
    "if custom_model_url_text.value:\n",
    "    !wget -nc --content-disposition {custom_model_url_text.value}\n",
    "    \n",
    "os.chdir(vae_dir)\n",
    "    \n",
    "if vaes_name.value:\n",
    "    vaes_url = vaes.get(vaes_name.value)\n",
    "    vaes_file = os.path.basename(vaes_url)\n",
    "    if not os.path.exists(os.path.join(vae_dir, vaes_file)):\n",
    "        !wget {vaes_url}\n",
    "    else:\n",
    "        print(f\"Vae Model '{vaes_file}' already exists in the directory. Skipping download.\")\n",
    "\n",
    "if vaes_custom.value:\n",
    "    !wget -nc --content-disposition {vaes_custom.value}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c02badb-dd35-4185-aabe-be9bf50de630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375cef530b3b427b90eec368f29b041b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='Convert to RGB with white background', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "convert = widgets.Checkbox(value=False, description=\"Convert to RGB with white background\", layout=widgets.Layout(width=\"auto\"))\n",
    "random_color = widgets.Checkbox(value=False, description=\"Use random color background\", layout=widgets.Layout(width=\"auto\"))\n",
    "recursive = widgets.Checkbox(value=False, description=\"Process subfolders as well\", layout=widgets.Layout(width=\"auto\"))\n",
    "\n",
    "def update_random_color_checkbox(change):\n",
    "    random_color.disabled = not change[\"new\"]\n",
    "\n",
    "convert.observe(update_random_color_checkbox, \"value\")\n",
    "\n",
    "widget_box = widgets.VBox([convert, random_color, recursive])\n",
    "widget_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c38184-0a64-49bb-8147-f5e897e309e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11715.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have been converted\n",
      "all good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @title ## 4.1. Data Cleaning\n",
    "import os\n",
    "import random\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "os.chdir(root_dir)\n",
    "\n",
    "test = os.listdir(train_data_dir)\n",
    "\n",
    "batch_size = 32\n",
    "supported_types = [\n",
    "    \".png\",\n",
    "    \".jpg\",\n",
    "    \".jpeg\",\n",
    "    \".webp\",\n",
    "    \".bmp\",\n",
    "    \".caption\",\n",
    "    \".npz\",\n",
    "    \".txt\",\n",
    "    \".json\",\n",
    "]\n",
    "\n",
    "background_colors = [\n",
    "    (255, 255, 255),\n",
    "    (0, 0, 0),\n",
    "    (255, 0, 0),\n",
    "    (0, 255, 0),\n",
    "    (0, 0, 255),\n",
    "    (255, 255, 0),\n",
    "    (255, 0, 255),\n",
    "    (0, 255, 255),\n",
    "]\n",
    "\n",
    "def clean_directory(directory):\n",
    "    for item in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, item)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_ext = os.path.splitext(item)[1]\n",
    "            if file_ext not in supported_types:\n",
    "                print(f\"Deleting file {item} from {directory}\")\n",
    "                os.remove(file_path)\n",
    "        elif os.path.isdir(file_path) and recursive:\n",
    "            clean_directory(file_path)\n",
    "\n",
    "def process_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img_dir, image_name = os.path.split(image_path)\n",
    "\n",
    "    if img.mode in (\"RGBA\", \"LA\"):\n",
    "        if random_color.value:\n",
    "            background_color = random.choice(background_colors)\n",
    "        else:\n",
    "            background_color = (255, 255, 255)\n",
    "        bg = Image.new(\"RGB\", img.size, background_color)\n",
    "        bg.paste(img, mask=img.split()[-1])\n",
    "\n",
    "        if image_name.endswith(\".webp\"):\n",
    "            bg = bg.convert(\"RGB\")\n",
    "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
    "            bg.save(new_image_path, \"JPEG\")\n",
    "            os.remove(image_path)\n",
    "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
    "        else:\n",
    "            bg.save(image_path, \"PNG\")\n",
    "            print(f\" Converted image: {image_name}\")\n",
    "    else:\n",
    "        if image_name.endswith(\".webp\"):\n",
    "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
    "            img.save(new_image_path, \"JPEG\")\n",
    "            os.remove(image_path)\n",
    "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
    "        else:\n",
    "            img.save(image_path, \"PNG\")\n",
    "\n",
    "def find_images(directory):\n",
    "    images = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\") or file.endswith(\".webp\"):\n",
    "                images.append(os.path.join(root, file))\n",
    "    return images\n",
    "\n",
    "clean_directory(train_data_dir)\n",
    "images = find_images(train_data_dir)\n",
    "num_batches = len(images) // batch_size + 1\n",
    "\n",
    "if convert.value:\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for i in tqdm(range(num_batches)):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            batch = images[start:end]\n",
    "            executor.map(process_image, batch)\n",
    "\n",
    "    print(\"All images have been converted\")\n",
    "print('all good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6077c77a-f3dc-4fae-b0ed-e8c5b8c7fa25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc75d9be5464492a814165aa324a355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Captioning:', layout=Layout(width='auto'), options=('BLIP', 'Waifu', 'No …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "captioning = widgets.Dropdown(\n",
    "    options=[\"BLIP\", \"Waifu\", \"No captions\"],\n",
    "    value=\"BLIP\",\n",
    "    description=\"Captioning:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "batch_size = widgets.IntSlider(\n",
    "    value=8,\n",
    "    min=1,\n",
    "    max=16,\n",
    "    step=1,\n",
    "    description=\"Batch Size:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "max_data_loader_n_workers = widgets.IntSlider(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=8,\n",
    "    step=1,\n",
    "    description=\"Data Loader Workers:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "beam_search = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Beam Search\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "min_length = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description=\"Minimum Length:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "max_length = widgets.IntSlider(\n",
    "    value=75,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description=\"Maximum Length:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "recursive = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Recursive\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "verbose_logging = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Verbose Logging\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "model = widgets.Dropdown(\n",
    "    options=[\n",
    "        \"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\",\n",
    "        \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\",\n",
    "        \"SmilingWolf/wd-v1-4-convnext-tagger-v2\",\n",
    "        \"SmilingWolf/wd-v1-4-vit-tagger-v2\"\n",
    "    ],\n",
    "    value=\"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\",\n",
    "    description=\"Model:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "undesired_tags = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Undesired Tags:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "general_threshold = widgets.FloatSlider(\n",
    "    value=0.35,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description=\"General Threshold:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "character_threshold = widgets.FloatSlider(\n",
    "    value=0.35,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description=\"Character Threshold:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}  \n",
    ")\n",
    "\n",
    "widget_box = widgets.VBox([\n",
    "    captioning,\n",
    "    batch_size,\n",
    "    max_data_loader_n_workers,\n",
    "    beam_search,\n",
    "    min_length,\n",
    "    max_length,\n",
    "    recursive,\n",
    "    verbose_logging,\n",
    "    model,\n",
    "    undesired_tags,\n",
    "    general_threshold,\n",
    "    character_threshold\n",
    "])\n",
    "\n",
    "def caption_default():\n",
    "    model.disabled = True\n",
    "    undesired_tags.disabled = True\n",
    "    general_threshold.disabled = True\n",
    "    character_threshold.disabled = True\n",
    "\n",
    "def on_captioning_change(change):\n",
    "    \n",
    "    if change.new == \"Waifu\":\n",
    "        model.disabled = False\n",
    "        undesired_tags.disabled = False\n",
    "        general_threshold.disabled = False\n",
    "        character_threshold.disabled = False\n",
    "    else:\n",
    "        model.disabled = True\n",
    "        undesired_tags.disabled = True\n",
    "        general_threshold.disabled = True\n",
    "        character_threshold.disabled = True\n",
    "\n",
    "caption_default()\n",
    "captioning.observe(on_captioning_change, names='value')\n",
    "\n",
    "widget_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fbb868-0569-4f13-a4b7-1cd18ce004c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-02 12:41:48.539810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "load images from /home/studio-lab-user/sagemaker-studiolab-notebooks/train_data\n",
      "found 24 images.\n",
      "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███| 232k/232k [00:00<00:00, 29.8MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|███| 28.0/28.0 [00:00<00:00, 4.70kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████| 570/570 [00:00<00:00, 347kB/s]\n",
      "100%|██████████████████████████████████████| 1.66G/1.66G [00:29<00:00, 60.9MB/s]\n",
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
      "BLIP loaded\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/0530dfe0-c3b8-11eb-aff9-7670003c98ba.jpg a woman in a red dress posing for a picture\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/08f5d98b9e9e9f91fddfb1d4a9ad8ae6e3-13-christinahendricks.jpg a woman in a red dress posing for a picture\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/1C4162570-tdy-121005-Christina-Hendricks-cover.jpg a woman with red hair and a black dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/258506_v9_bc.jpg a woman with red hair and a red lip\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/5d976948-0001-0004-0000-000001480202_w1600_r1.4326647564469914_fpx41.87_fpy50.jpg a woman with a hat and dress posing for a picture\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/9f78246e369a8a6b4c483b4c63e78b40cc-41---.2x.rsquare.w536.jpg a woman in a dress on a red carpet\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/Christina-H-61ed92563ea94d49a33bf8ca581d4fb7.jpg a woman with red hair and a dress standing in front of a wall of flowers\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/Christina-Hendricks-Seen-Mingling-at-Party-After-Geoffrey-Arend-Split.jpg a woman in a green dress posing for a picture\n",
      " 33%|███████████████                              | 1/3 [00:05<00:11,  5.87s/it]/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/Christina-Hendricks.jpg a woman with red hair and a tan dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/Christina-Hendricks2.jpg a woman with red hair and a green dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/Christina_Hendricks_at_PaleyFest_2014.jpg a woman with red hair and a green dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/GettyImages-1401105089-d9915a2c93b94b0a8f8b05de7cfcb89c.jpg a woman with red hair and a bright dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/Getty_ChristinaHendricks.jpg a woman with a big breast posing for a picture\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/MV5BMjA5Njg3NDkxNV5BMl5BanBnXkFtZTgwNDczMTgyODE@._V1_.jpg a woman with red hair and a blue shirt\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/Unbenannt.jpg a woman in a black dress posing for a picture\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/christina-hendricks-64522d0052e3f.jpg a woman with red hair and a black dress\n",
      " 67%|██████████████████████████████               | 2/3 [00:07<00:03,  3.68s/it]/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/christina-hendricks-mad-men-s3.jpg a woman sitting on the floor with a plate of food\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/christina-hendricks-then-and-now-ss-2.jpg a woman with red hair and a silver dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/christina-hendricks-then-and-now-ss-27.jpg a woman with red hair and a blue dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/christina-hendricks-toy-story-4-premiere.jpg a woman with red hair and a floral dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/christina-hendricks-w-893.jpg a woman with a red hair and a necklace\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/christina-hendricks01.jpg a woman with red hair and earrings looking at the camera\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/media.media.d2f2d9d1-efbd-422a-a627-95294534d516.original1024.jpg a woman with red hair and a gold dress\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data/vO59Bd8881Iz2DjfbTvq1vHTpW8.jpg a woman with red hair and a blue shirt\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:08<00:00,  2.99s/it]\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#@title ### 4.2.1. BLIP Captioning\n",
    "# Use BLIP for general images\n",
    "# Use Waifu for anime/manga images\n",
    "import os\n",
    "\n",
    "os.chdir(finetune_dir)\n",
    "\n",
    "if captioning.value == \"BLIP\":\n",
    "    config = {\n",
    "        \"_train_data_dir\" : train_data_dir,\n",
    "        \"batch_size\" : batch_size.value,\n",
    "        \"beam_search\" : beam_search.value,\n",
    "        \"min_length\" : min_length.value,\n",
    "        \"max_length\" : max_length.value,\n",
    "        \"debug\" : verbose_logging.value,\n",
    "        \"caption_extension\" : \".caption\",\n",
    "        \"max_data_loader_n_workers\" : max_data_loader_n_workers.value,\n",
    "        \"recursive\" : recursive.value\n",
    "    }\n",
    "\n",
    "elif captioning.value == \"Waifu\":\n",
    "    config = {\n",
    "        \"_train_data_dir\": train_data_dir,\n",
    "        \"batch_size\": batch_size.value,\n",
    "        \"repo_id\": model.value,\n",
    "        \"recursive\": recursive.value,\n",
    "        \"remove_underscore\": True,\n",
    "        \"general_threshold\": general_threshold.value,\n",
    "        \"character_threshold\": character_threshold.value,\n",
    "        \"caption_extension\": \".txt\",\n",
    "        \"max_data_loader_n_workers\": max_data_loader_n_workers.value,\n",
    "        \"debug\": verbose_logging.value,\n",
    "        \"undesired_tags\": undesired_tags.value\n",
    "    }\n",
    "\n",
    "else:\n",
    "    print(\"No captioning option selected. Skipping captioning process.\")\n",
    "\n",
    "if captioning.value == \"BLIP\" or captioning == \"Waifu\":\n",
    "    args = \"\"\n",
    "    for k, v in config.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            args += f'\"{v}\" '\n",
    "        elif isinstance(v, str):\n",
    "            args += f'--{k}=\"{v}\" '\n",
    "        elif isinstance(v, bool) and v:\n",
    "            args += f\"--{k} \"\n",
    "        elif isinstance(v, float) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "        elif isinstance(v, int) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "\n",
    "    final_args = f\"python make_captions.py {args}\" if captioning.value == \"BLIP\" else f\"python tag_images_by_wd14_tagger.py {args}\"\n",
    "\n",
    "    os.chdir(finetune_dir)\n",
    "    !{final_args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f0f3b9-7772-42d8-b247-7c5fa9a890e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bbbbf77f1a433fab5074ab62400d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Extension:', layout=Layout(width='auto'), options=('.txt', '.caption'), s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title ### 4.2.3. Custom Caption/Tag config\n",
    "import ipywidgets as widgets\n",
    "\n",
    "extension = widgets.Dropdown(\n",
    "    options=[\".txt\", \".caption\"],\n",
    "    value=\".txt\",\n",
    "    description=\"Extension:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "custom_tag = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Custom Tag:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "keyword = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Keyword replaced by custom tag:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "sub_folder = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Subfolder:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "append = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Append Custom Tags\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "prefix_tag = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Prefix Custom Tags\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "remove_tag = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Remove Captions/Tags (Only this option will be executed if checked)\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "recursive = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Recursive\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "widget_box = widgets.VBox([\n",
    "    extension,\n",
    "    custom_tag,\n",
    "    keyword,\n",
    "    sub_folder,\n",
    "    append,\n",
    "    prefix_tag,\n",
    "    remove_tag,\n",
    "    recursive\n",
    "])\n",
    "\n",
    "widget_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04899993-3d49-43a4-b88c-0f4b6947255e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ### 4.2.3. Custom Caption/Tag\n",
    "import os\n",
    "\n",
    "os.chdir(root_dir)\n",
    "\n",
    "if sub_folder.value == \"\":\n",
    "    image_dir = train_data_dir\n",
    "elif sub_folder.value == \"--all\":\n",
    "    image_dir = train_data_dir\n",
    "    recursive = True\n",
    "else:\n",
    "    image_dir = os.path.join(train_data_dir, sub_folder.value)\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    "\n",
    "def write_file(filename, contents):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "def process_tags(filename, custom_tag, append, prefix_tag, remove_tag, keyword):\n",
    "    contents = read_file(filename)\n",
    "    tags = [tag.strip() for tag in contents.split(',')]\n",
    "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
    "\n",
    "    for custom_tag in custom_tags:\n",
    "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
    "        if remove_tag:\n",
    "            while custom_tag in tags:\n",
    "                tags.remove(custom_tag)\n",
    "        else:\n",
    "            for i in range(len(tags)):\n",
    "                if keyword in tags[i]:\n",
    "                    tags[i] = tags[i].replace(keyword, custom_tag)\n",
    "            if append:\n",
    "                tags.append(custom_tag)\n",
    "            if prefix_tag:\n",
    "                tags.insert(0, custom_tag)\n",
    "\n",
    "    contents = ', '.join(tags)\n",
    "    write_file(filename, contents)\n",
    "\n",
    "def process_directory(image_dir, tag, append, prefix_tag, remove_tag, recursive, keyword):\n",
    "    for filename in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        \n",
    "        if os.path.isdir(file_path) and recursive:\n",
    "            process_directory(file_path, tag, append, prefix_tag, remove_tag, recursive, keyword)\n",
    "        elif filename.endswith(extension.value):\n",
    "            process_tags(file_path, tag, append, prefix_tag, remove_tag, keyword)\n",
    "\n",
    "tag = custom_tag.value\n",
    "\n",
    "if not any(\n",
    "    [filename.endswith(extension.value) for filename in os.listdir(image_dir)]\n",
    "):\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n",
    "            open(\n",
    "                os.path.join(image_dir, filename.split(\".\")[0] + extension.value),\n",
    "                \"w\",\n",
    "            ).close()\n",
    "\n",
    "if custom_tag.value:\n",
    "    process_directory(image_dir, tag, append.value, prefix_tag.value, remove_tag.value, recursive.value, keyword.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2390d48b-05f1-459a-960d-891c243aab6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbafca9f0f0f4ce1ad7fdc08f3a2234d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='v2', layout=Layout(width='auto'), style=DescriptionStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title ## 5.1. Model Config widget\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "pretrained_model_options = [\n",
    "    os.path.join(pretrained_dir, filename)\n",
    "    for filename in os.listdir(pretrained_dir)\n",
    "    if os.path.isfile(os.path.join(pretrained_dir, filename))\n",
    "]\n",
    "\n",
    "vae_options = [\n",
    "    os.path.join(vae_dir, filename)\n",
    "    for filename in os.listdir(vae_dir)\n",
    "    if os.path.isfile(os.path.join(vae_dir, filename))\n",
    "]\n",
    "\n",
    "resume_options = [\n",
    "    os.path.join(dreambooth_output_dir, filename)\n",
    "    for filename in os.listdir(dreambooth_output_dir)\n",
    "    if os.path.isfile(os.path.join(dreambooth_output_dir, filename))\n",
    "]\n",
    "\n",
    "v2 = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"v2\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "v_parameterization = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"v_parameterization\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "project_name = widgets.Text(\n",
    "    value=\"Last\",\n",
    "    description=\"Project Name:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "pretrained_model_name_or_path = widgets.Dropdown(\n",
    "    options=pretrained_model_options+resume_options,\n",
    "    description=\"Pretrained Model:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "vae = widgets.Dropdown(\n",
    "    options=vae_options,\n",
    "    description=\"VAE:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "resume_path = widgets.Dropdown(\n",
    "    options=[\"\"]+resume_options,\n",
    "    description=\"Resume Path:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "widget_box = widgets.VBox([\n",
    "    v2,\n",
    "    v_parameterization,\n",
    "    project_name,\n",
    "    pretrained_model_name_or_path,\n",
    "    vae,\n",
    "    resume_path\n",
    "])\n",
    "\n",
    "widget_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fd8a158-6287-4df3-bf2a-d22b7047c51f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930588b746ef4605bb8fae014c80e8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=10, description='Dataset Repeats:', layout=Layout(width='auto'), min=1, style=S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title ## 5.2. Dataset Config widget\n",
    "# @markdown default values are designed for `one concept` training. Refer to this [guide](https://rentry.org/kohyaminiguide#b-multi-concept-training) for multi-concept training.\n",
    "import ipywidgets as widgets\n",
    "\n",
    "dataset_repeats = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description=\"Dataset Repeats:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "activation_word = widgets.Text(\n",
    "    value=\"mksks style\",\n",
    "    description=\"Activation Word:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "caption_extension = widgets.Dropdown(\n",
    "    options=[\"none\", \".txt\", \".caption\"],\n",
    "    value=\".caption\",\n",
    "    description=\"Caption Extension:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "token_to_captions = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Token to Captions\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "resolution = widgets.IntSlider(\n",
    "    value=512,\n",
    "    min=512,\n",
    "    max=1024,\n",
    "    step=128,\n",
    "    description=\"Resolution:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "flip_aug = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Flip Augmentation\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "keep_tokens = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description=\"Keep Tokens:\",\n",
    "    layout=widgets.Layout(width=\"auto\"),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "widget_box = widgets.VBox([\n",
    "    dataset_repeats,\n",
    "    activation_word,\n",
    "    caption_extension,\n",
    "    token_to_captions,\n",
    "    resolution,\n",
    "    flip_aug,\n",
    "    keep_tokens\n",
    "])\n",
    "\n",
    "widget_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b4c3081-4c74-4f87-9bcf-e957bd2ce411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[datasets]]\n",
      "resolution = 512\n",
      "min_bucket_reso = 256\n",
      "max_bucket_reso = 1024\n",
      "caption_dropout_rate = 0\n",
      "caption_tag_dropout_rate = 0\n",
      "caption_dropout_every_n_epochs = 0\n",
      "flip_aug = false\n",
      "color_aug = false\n",
      "[[datasets.subsets]]\n",
      "image_dir = \"/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data\"\n",
      "class_tokens = \"mksks style\"\n",
      "num_repeats = 10\n",
      "\n",
      "\n",
      "[general]\n",
      "enable_bucket = true\n",
      "caption_extension = \".caption\"\n",
      "shuffle_caption = true\n",
      "keep_tokens = 0\n",
      "bucket_reso_steps = 64\n",
      "bucket_no_upscale = false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title ## 5.2. Dataset Config\n",
    "import toml\n",
    "import glob\n",
    "\n",
    "if ',' in activation_word.value or ' ' in activation_word.value:\n",
    "    words = activation_word.value.replace(',', ' ').split()\n",
    "    class_token = words[-1]\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    "\n",
    "\n",
    "def write_file(filename, contents):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "\n",
    "def get_supported_images(folder):\n",
    "    supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
    "    return [file for ext in supported_extensions for file in glob.glob(f\"{folder}/*{ext}\")]\n",
    "\n",
    "\n",
    "def get_subfolders_with_supported_images(folder):\n",
    "    subfolders = [os.path.join(folder, subfolder) for subfolder in os.listdir(folder) if os.path.isdir(os.path.join(folder, subfolder))]\n",
    "    return [subfolder for subfolder in subfolders if len(get_supported_images(subfolder)) > 0]\n",
    "\n",
    "\n",
    "def process_tags(filename, custom_tag, remove_tag):\n",
    "    contents = read_file(filename)\n",
    "    tags = [tag.strip() for tag in contents.split(',')]\n",
    "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
    "\n",
    "    for custom_tag in custom_tags:\n",
    "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
    "        if remove_tag:\n",
    "            while custom_tag in tags:\n",
    "                tags.remove(custom_tag)\n",
    "        else:\n",
    "            if custom_tag not in tags:\n",
    "                tags.insert(0, custom_tag)\n",
    "\n",
    "    contents = ', '.join(tags)\n",
    "    write_file(filename, contents)\n",
    "\n",
    "\n",
    "def process_folder_recursively(folder):\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(caption_extension.value):\n",
    "                file_path = os.path.join(root, file)\n",
    "                extracted_class_token = get_class_token_from_folder_name(root, folder)\n",
    "                train_supported_images = get_supported_images(train_data_dir)\n",
    "                tag = extracted_class_token if extracted_class_token else activation_word.value if train_supported_images else \"\"\n",
    "                if not tag == \"\":\n",
    "                    process_tags(file_path, tag, remove_tag=(not token_to_captions.value))\n",
    "\n",
    "\n",
    "def get_num_repeats(folder):\n",
    "    folder_name = os.path.basename(folder)\n",
    "    try:\n",
    "        repeats, _ = folder_name.split('_', 1)\n",
    "        num_repeats = int(repeats)\n",
    "    except ValueError:\n",
    "        num_repeats = 1\n",
    "\n",
    "    return num_repeats\n",
    "\n",
    "\n",
    "def get_class_token_from_folder_name(folder, parent_folder):\n",
    "    if folder == parent_folder:\n",
    "        return class_token\n",
    "\n",
    "    folder_name = os.path.basename(folder)\n",
    "    try:\n",
    "        _, concept = folder_name.split('_', 1)\n",
    "        return concept\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "        \n",
    "train_supported_images = get_supported_images(train_data_dir)\n",
    "train_subfolders = get_subfolders_with_supported_images(train_data_dir)\n",
    "reg_supported_images = get_supported_images(reg_data_dir)\n",
    "reg_subfolders = get_subfolders_with_supported_images(reg_data_dir)\n",
    "\n",
    "subsets = []\n",
    "\n",
    "config = {\n",
    "    \"general\": {\n",
    "        \"enable_bucket\": True,\n",
    "        \"caption_extension\": caption_extension.value,\n",
    "        \"shuffle_caption\": True,\n",
    "        \"keep_tokens\": keep_tokens.value,\n",
    "        \"bucket_reso_steps\": 64,\n",
    "        \"bucket_no_upscale\": False,\n",
    "    },\n",
    "    \"datasets\": [\n",
    "        {\n",
    "            \"resolution\": resolution.value,\n",
    "            \"min_bucket_reso\": 320 if resolution.value > 640 else 256,\n",
    "            \"max_bucket_reso\": 1280 if resolution.value > 640 else 1024,\n",
    "            \"caption_dropout_rate\": 0,\n",
    "            \"caption_tag_dropout_rate\": 0,\n",
    "            \"caption_dropout_every_n_epochs\": 0,\n",
    "            \"flip_aug\": flip_aug.value,\n",
    "            \"color_aug\": False,\n",
    "            \"face_crop_aug_range\": None,\n",
    "            \"subsets\": subsets,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "if token_to_captions.value and keep_tokens.value < 2:\n",
    "    keep_tokens.value = 1\n",
    "\n",
    "if caption_extension.value != \"none\":\n",
    "    process_folder_recursively(train_data_dir)\n",
    "\n",
    "if train_supported_images:\n",
    "    subsets.append({\n",
    "        \"image_dir\": train_data_dir,\n",
    "        \"class_tokens\": activation_word.value,\n",
    "        \"num_repeats\": dataset_repeats.value,\n",
    "    })\n",
    "\n",
    "for subfolder in train_subfolders:\n",
    "    num_repeats = get_num_repeats(subfolder)\n",
    "    extracted_class_token = get_class_token_from_folder_name(subfolder, train_data_dir.value)\n",
    "    subsets.append({\n",
    "        \"image_dir\": subfolder,\n",
    "        \"class_tokens\": extracted_class_token if extracted_class_token else None,\n",
    "        \"num_repeats\": num_repeats,\n",
    "    })\n",
    "\n",
    "if reg_supported_images:\n",
    "    subsets.append({\n",
    "        \"is_reg\": True,\n",
    "        \"image_dir\": reg_data_dir,\n",
    "        \"class_tokens\": class_token if 'class_token' in globals() else None,\n",
    "        \"num_repeats\": 1,\n",
    "    })\n",
    "\n",
    "for subfolder in reg_subfolders:\n",
    "    extracted_class_token = get_class_token_from_folder_name(subfolder, reg_data_dir.value)\n",
    "    subsets.append({\n",
    "        \"is_reg\": True,\n",
    "        \"image_dir\": subfolder,\n",
    "        \"class_tokens\": extracted_class_token if extracted_class_token else None,\n",
    "        \"num_repeats\": num_repeats,\n",
    "    })\n",
    "\n",
    "for subset in subsets:\n",
    "    if not glob.glob(f\"{subset['image_dir']}/*.txt\"):\n",
    "        subset[\"class_tokens\"] = activation_word.value\n",
    "\n",
    "dataset_config = os.path.join(dreambooth_config_dir, \"dataset_config.toml\")\n",
    "\n",
    "for key in config:\n",
    "    if isinstance(config[key], dict):\n",
    "        for sub_key in config[key]:\n",
    "            if config[key][sub_key] == \"\":\n",
    "                config[key][sub_key] = None\n",
    "    elif config[key] == \"\":\n",
    "        config[key] = None\n",
    "\n",
    "config_str = toml.dumps(config)\n",
    "\n",
    "with open(dataset_config, \"w\") as f:\n",
    "    f.write(config_str)\n",
    "\n",
    "print(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2179081d-2e7f-4d6c-a024-4ce9f25a3fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998d3f402d82412f9c33edc94dbf03b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatText(value=-1.0, description='min_snr_gamma:', step=0.01, style=DescriptionStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title ## 5.3. Optimizer Config\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "min_snr_gamma = widgets.FloatText(\n",
    "    value=-1,\n",
    "    description='min_snr_gamma:',\n",
    "    step=0.01,\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "optimizer_type = widgets.Dropdown(\n",
    "    options=[\"AdamW\", \"AdamW8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation\", \"AdaFactor\"],\n",
    "    value=\"AdamW8bit\",\n",
    "    description='optimizer_type:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "optimizer_args = widgets.Text(\n",
    "    value=\"\",\n",
    "    description='optimizer_args:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "learning_rate = widgets.FloatText(\n",
    "    value=2e-6,\n",
    "    description='learning_rate:',\n",
    "    step=1e-7,\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "stop_train_text_encoder = widgets.IntText(\n",
    "    value=-1,\n",
    "    description='stop_train_text_encoder:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "lr_scheduler = widgets.Dropdown(\n",
    "    options=[\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"],\n",
    "    value=\"constant\",\n",
    "    description='lr_scheduler:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "lr_warmup_steps = widgets.IntText(\n",
    "    value=0,\n",
    "    description='lr_warmup_steps:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "lr_scheduler_num_cycles = widgets.IntText(\n",
    "    value=0,\n",
    "    description='lr_scheduler_num_cycles:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "lr_scheduler_power = widgets.IntText(\n",
    "    value=0,\n",
    "    description='lr_scheduler_power:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "widget_list = [\n",
    "    min_snr_gamma,\n",
    "    optimizer_type,\n",
    "    optimizer_args,\n",
    "    learning_rate,\n",
    "    stop_train_text_encoder,\n",
    "    lr_scheduler,\n",
    "    lr_warmup_steps,\n",
    "    lr_scheduler_num_cycles,\n",
    "    lr_scheduler_power,\n",
    "]\n",
    "\n",
    "widget_box = widgets.VBox(widget_list)\n",
    "widget_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc13ae4e-cd88-489c-aaed-8287f43ac72c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d82add45c9f45f195b6099fdbea34d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=True, description='enable_sample_prompt:'), IntText(value=1, description='sample…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title ## 5.4. Training Config widget\n",
    "import ipywidgets as widgets\n",
    "\n",
    "enable_sample_prompt = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='enable_sample_prompt:',\n",
    ")\n",
    "\n",
    "samples_per_prompt = widgets.IntText(\n",
    "    value=1,\n",
    "    description='samples per prompt:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "\n",
    "sampler = widgets.Dropdown(\n",
    "    options=[\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\", \"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"],\n",
    "    value=\"ddim\",\n",
    "    description='sampler:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "noise_offset = widgets.FloatText(\n",
    "    value=0.0,\n",
    "    description='noise_offset:',\n",
    "    step=0.01,\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "max_train_steps = widgets.IntText(\n",
    "    value=2500,\n",
    "    description='max_train_steps:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "vae_batch_size = widgets.IntText(\n",
    "    value=1,\n",
    "    description='vae_batch_size:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "train_batch_size = widgets.IntText(\n",
    "    value=4,\n",
    "    description='train_batch_size:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "mixed_precision = widgets.Dropdown(\n",
    "    options=[\"no\", \"fp16\", \"bf16\"],\n",
    "    value=\"fp16\",\n",
    "    description='mixed_precision:',\n",
    "    disabled=False,\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "save_state = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='save_state:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "save_precision = widgets.Dropdown(\n",
    "    options=[\"float\", \"fp16\", \"bf16\"],\n",
    "    value=\"fp16\",\n",
    "    description='save_precision:',\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "save_n_epoch_ratio = widgets.FloatText(\n",
    "    value=1,\n",
    "    description='save_n_epoch_ratio:',\n",
    "    step=0.1,\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "save_model_as = widgets.Dropdown(\n",
    "    options=[\"ckpt\", \"safetensors\", \"diffusers\", \"diffusers_safetensors\"],\n",
    "    value=\"ckpt\",\n",
    "    description='save_model_as:',\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "max_token_length = widgets.IntText(\n",
    "    value=225,\n",
    "    description='max_token_length:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "clip_skip = widgets.IntText(\n",
    "    value=2,\n",
    "    description='clip_skip:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "gradient_checkpointing = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='gradient_checkpointing:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "gradient_accumulation_steps = widgets.IntText(\n",
    "    value=1,\n",
    "    description='gradient_accumulation_steps:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "seed = widgets.IntText(\n",
    "    value=-1,\n",
    "    description='seed:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "huggingface_repo_id = widgets.Text(\n",
    "    value=\"xxthekingxx/myHendricks2\",\n",
    "    description='huggingface repo id:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "huggingface_path_in_repo = widgets.Text(\n",
    "    value=\"mymodel\",\n",
    "    description='path in repo:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "huggingface_token = widgets.Text(\n",
    "    value=\"\",\n",
    "    description='huggingface write token:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "save_checkpoint_local  = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='save epochs local?:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "async_upload = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='upload asynchronously (requires save local):',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "prior_loss_weight = widgets.FloatText(\n",
    "    value=1.0,\n",
    "    description='prior_loss_weight:',\n",
    "    step=0.1,\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "widget_list = [\n",
    "    enable_sample_prompt,\n",
    "    samples_per_prompt,\n",
    "    sampler,\n",
    "    noise_offset,\n",
    "    max_train_steps,\n",
    "    vae_batch_size,\n",
    "    train_batch_size,\n",
    "    mixed_precision,\n",
    "    save_checkpoint_local,\n",
    "    huggingface_repo_id,\n",
    "    huggingface_path_in_repo,\n",
    "    huggingface_token,\n",
    "    async_upload,\n",
    "    save_state,\n",
    "    save_precision,\n",
    "    save_n_epoch_ratio,\n",
    "    save_model_as,\n",
    "    max_token_length,\n",
    "    clip_skip,\n",
    "    gradient_checkpointing,\n",
    "    gradient_accumulation_steps,\n",
    "    seed,\n",
    "    prior_loss_weight,\n",
    "]\n",
    "\n",
    "widget_box = widgets.VBox(widget_list)\n",
    "widget_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6878dc3a-18d4-41ee-b6c7-797c12ddc796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_arguments]\n",
      "v2 = false\n",
      "v_parameterization = false\n",
      "pretrained_model_name_or_path = \"/home/studio-lab-user/sagemaker-studiolab-notebooks/pretrained_model/realisticVisionV20_v20NoVAE.safetensors\"\n",
      "vae = \"/home/studio-lab-user/sagemaker-studiolab-notebooks/vae/vae-ft-mse-840000-ema-pruned.ckpt\"\n",
      "\n",
      "[optimizer_arguments]\n",
      "optimizer_type = \"AdamW8bit\"\n",
      "learning_rate = 4e-6\n",
      "max_grad_norm = 1.0\n",
      "lr_scheduler = \"cosine_with_restarts\"\n",
      "lr_warmup_steps = 0\n",
      "lr_scheduler_num_cycles = 0\n",
      "\n",
      "[dataset_arguments]\n",
      "cache_latents = true\n",
      "debug_dataset = false\n",
      "vae_batch_size = 1\n",
      "\n",
      "[huggingface_arguments]\n",
      "huggingface_path_in_repo = \"mymodel\"\n",
      "async_upload = false\n",
      "huggingface_repo_id = \"xxthekingxx/myHendricks4\"\n",
      "\n",
      "[training_arguments]\n",
      "output_dir = \"/home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/output\"\n",
      "output_name = \"Hendricks4\"\n",
      "save_precision = \"fp16\"\n",
      "save_n_epoch_ratio = 1.0\n",
      "save_checkpoint_local = false\n",
      "save_state = false\n",
      "train_batch_size = 4\n",
      "max_token_length = 225\n",
      "mem_eff_attn = false\n",
      "xformers = true\n",
      "max_train_steps = 400\n",
      "max_data_loader_n_workers = 8\n",
      "persistent_data_loader_workers = true\n",
      "gradient_checkpointing = false\n",
      "gradient_accumulation_steps = 1\n",
      "mixed_precision = \"fp16\"\n",
      "clip_skip = 2\n",
      "logging_dir = \"/home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/logs\"\n",
      "log_prefix = \"Hendricks4\"\n",
      "\n",
      "[sample_prompt_arguments]\n",
      "samples_per_prompt = 4\n",
      "sample_every_n_steps = 100\n",
      "sample_sampler = \"euler_a\"\n",
      "\n",
      "[dreambooth_arguments]\n",
      "prior_loss_weight = 1.0\n",
      "\n",
      "[saving_arguments]\n",
      "save_model_as = \"ckpt\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "import os\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "sample_str = f\"\"\"\n",
    "  xhendx in a swimsuit \\\n",
    "  --n lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry \\\n",
    "  --w 512 \\\n",
    "  --h 768 \\\n",
    "  --l 7 \\\n",
    "  --s 35    \n",
    "\"\"\"\n",
    "\n",
    "config = {\n",
    "    \"model_arguments\": {\n",
    "        \"v2\": v2.value,\n",
    "        \"v_parameterization\": v_parameterization.value if v2.value and v_parameterization.value else False,\n",
    "        \"pretrained_model_name_or_path\": pretrained_model_name_or_path.value,\n",
    "        \"vae\": vae.value,\n",
    "    },\n",
    "    \"optimizer_arguments\": {\n",
    "        \"min_snr_gamma\": min_snr_gamma.value if not min_snr_gamma.value == -1 else None,\n",
    "        \"optimizer_type\": optimizer_type.value,\n",
    "        \"learning_rate\": learning_rate.value,\n",
    "        \"max_grad_norm\": 1.0,\n",
    "        \"stop_train_text_encoder\": stop_train_text_encoder.value if stop_train_text_encoder.value > 0 else None,\n",
    "        \"optimizer_args\": eval(optimizer_args.value) if optimizer_args.value else None,\n",
    "        \"lr_scheduler\": lr_scheduler.value,\n",
    "        \"lr_warmup_steps\": lr_warmup_steps.value,\n",
    "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles.value if lr_scheduler.value == \"cosine_with_restarts\" else None,\n",
    "        \"lr_scheduler_power\": lr_scheduler_power.value if lr_scheduler.value == \"polynomial\" else None,\n",
    "    },\n",
    "    \"dataset_arguments\": {\n",
    "        \"cache_latents\": True,\n",
    "        \"debug_dataset\": False,\n",
    "        \"vae_batch_size\": vae_batch_size.value,\n",
    "    },\n",
    "        \"huggingface_arguments\": {\n",
    "        \"repo_type\" : None,\n",
    "        \"huggingface_path_in_repo\": huggingface_path_in_repo.value,\n",
    "        \"huggingface_repo_visibility\" : None, #private if not \"public\"\n",
    "        \"huggingface_token\": huggingface_token.value,\n",
    "        \"async_upload\" : async_upload.value,\n",
    "        \"huggingface_repo_id\" : huggingface_repo_id.value,\n",
    "    },\n",
    "    \"training_arguments\": {\n",
    "        \"output_dir\": dreambooth_output_dir,\n",
    "        \"output_name\": project_name.value,\n",
    "        \"save_precision\": save_precision.value,\n",
    "        \"save_every_n_epochs\": None,\n",
    "        \"save_n_epoch_ratio\": save_n_epoch_ratio.value,\n",
    "        \"save_checkpoint_local\": save_checkpoint_local.value,\n",
    "        \"save_last_n_epochs\": None,\n",
    "        \"save_state\": save_state.value,\n",
    "        \"save_last_n_epochs_state\": None,\n",
    "        \"resume\": resume_path.value,\n",
    "        \"train_batch_size\": train_batch_size.value,\n",
    "        \"max_token_length\": 225,\n",
    "        \"mem_eff_attn\": False,\n",
    "        \"xformers\": True,\n",
    "        \"max_train_steps\": max_train_steps.value,\n",
    "        \"max_data_loader_n_workers\": 8,\n",
    "        \"persistent_data_loader_workers\": True,\n",
    "        \"seed\": seed.value if seed.value > 0 else None,\n",
    "        \"gradient_checkpointing\": gradient_checkpointing.value,\n",
    "        \"gradient_accumulation_steps\": gradient_accumulation_steps.value,\n",
    "        \"mixed_precision\": mixed_precision.value,\n",
    "        \"clip_skip\": clip_skip.value if not v2.value else None,\n",
    "        \"logging_dir\": dreambooth_logging_dir,\n",
    "        \"log_prefix\": project_name.value,\n",
    "        \"noise_offset\": noise_offset.value if noise_offset.value > 0 else None,\n",
    "    },\n",
    "    \"sample_prompt_arguments\": {\n",
    "        \"samples_per_prompt\" : samples_per_prompt.value,\n",
    "        \"sample_every_n_steps\": 100 if enable_sample_prompt.value else 999999,\n",
    "        \"sample_every_n_epochs\": None,\n",
    "        \"sample_sampler\": sampler.value,\n",
    "    },\n",
    "    \"dreambooth_arguments\": {\n",
    "        \"prior_loss_weight\": 1.0,\n",
    "    },\n",
    "    \"saving_arguments\": {\n",
    "        \"save_model_as\": save_model_as.value\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "config_path = os.path.join(dreambooth_config_dir, \"config_file.toml\")\n",
    "prompt_path = os.path.join(dreambooth_config_dir, \"sample_prompt.txt\")\n",
    "\n",
    "for key in config:\n",
    "    if isinstance(config[key], dict):\n",
    "        for sub_key in config[key]:\n",
    "            if config[key][sub_key] == \"\":\n",
    "                config[key][sub_key] = None\n",
    "    elif config[key] == \"\":\n",
    "        config[key] = None\n",
    "\n",
    "config_str = toml.dumps(config)\n",
    "\n",
    "def write_file(filename, contents):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "write_file(config_path, config_str)\n",
    "write_file(prompt_path, sample_str)\n",
    "    \n",
    "print(config_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "438b9f6d-99d1-407b-9ba7-1d35c7d0abb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-02 13:15:30.570365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-02 13:15:34.738108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading settings from /home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/config/config_file.toml...\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/config/config_file\n",
      "prepare tokenizer\n",
      "update token length: 225\n",
      "Load dataset config from /home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/config/dataset_config.toml\n",
      "prepare images.\n",
      "found directory /home/studio-lab-user/sagemaker-studiolab-notebooks/train_data contains 24 image files\n",
      "240 train images with repeating.\n",
      "0 reg images.\n",
      "no regularization images / 正則化画像が見つかりませんでした\n",
      "[Dataset 0]\n",
      "  batch_size: 4\n",
      "  resolution: (512, 512)\n",
      "  enable_bucket: True\n",
      "  min_bucket_reso: 256\n",
      "  max_bucket_reso: 1024\n",
      "  bucket_reso_steps: 64\n",
      "  bucket_no_upscale: False\n",
      "\n",
      "  [Subset 0 of Dataset 0]\n",
      "    image_dir: \"/home/studio-lab-user/sagemaker-studiolab-notebooks/train_data\"\n",
      "    image_count: 24\n",
      "    num_repeats: 10\n",
      "    shuffle_caption: True\n",
      "    keep_tokens: 0\n",
      "    caption_dropout_rate: 0\n",
      "    caption_dropout_every_n_epoches: 0\n",
      "    caption_tag_dropout_rate: 0\n",
      "    color_aug: False\n",
      "    flip_aug: False\n",
      "    face_crop_aug_range: None\n",
      "    random_crop: False\n",
      "    token_warmup_min: 1,\n",
      "    token_warmup_step: 0,\n",
      "    is_reg: False\n",
      "    class_tokens: mksks style\n",
      "    caption_extension: .caption\n",
      "\n",
      "\n",
      "[Dataset 0]\n",
      "loading image sizes.\n",
      "100%|█████████████████████████████████████████| 24/24 [00:00<00:00, 1894.73it/s]\n",
      "make buckets\n",
      "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
      "bucket 0: resolution (512, 512), count: 240\n",
      "mean ar error (without repeats): 0.0\n",
      "prepare accelerator\n",
      "Using accelerator 0.15.0 or above.\n",
      "load StableDiffusion checkpoint\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/safetensors/torch.py:98: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "loading u-net: <All keys matched successfully>\n",
      "loading vae: <All keys matched successfully>\n",
      "loading text encoder: <All keys matched successfully>\n",
      "load VAE: /home/studio-lab-user/sagemaker-studiolab-notebooks/vae/vae-ft-mse-840000-ema-pruned.ckpt\n",
      "additional VAE loaded\n",
      "Replace CrossAttention.forward to use xformers\n",
      "[Dataset 0]\n",
      "caching latents.\n",
      "100%|███████████████████████████████████████████| 24/24 [00:03<00:00,  6.52it/s]\n",
      "prepare optimizer, data loader etc.\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/bitsandbytes/cuda_setup/paths.py:93: UserWarning: /home/studio-lab-user/.conda/envs/default did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/cv2/../../lib64'), PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64')}\n",
      "  warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('unix')}\n",
      "  warn(\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 112\n",
      "CUDA SETUP: Loading binary /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda112.so...\n",
      "use 8-bit AdamW optimizer | {}\n",
      "running training / 学習開始\n",
      "  num train images * repeats / 学習画像の数×繰り返し回数: 240\n",
      "  num reg images / 正則化画像の数: 0\n",
      "  num batches per epoch / 1epochのバッチ数: 60\n",
      "  num epochs / epoch数: 7\n",
      "  batch size per device / バッチサイズ: 4\n",
      "  total train batch size (with parallel & distributed & accumulation) / 総バッチサイズ（並列学習、勾配合計含む）: 4\n",
      "  gradient ccumulation steps / 勾配を合計するステップ数 = 1\n",
      "  total optimization steps / 学習ステップ数: 400\n",
      "steps:   0%|                                            | 0/400 [00:00<?, ?it/s]epoch 1/7\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
      "steps:  15%|███▍                   | 60/400 [01:10<06:37,  1.17s/it, loss=0.129]epoch 2/7\n",
      "steps:  25%|█████▌                | 100/400 [01:59<05:58,  1.19s/it, loss=0.132]generating sample images at step / サンプル画像生成 ステップ: 100\n",
      "prompt: xhendx in a swimsuit  \n",
      "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
      "height: 768\n",
      "width: 512\n",
      "sample_steps: 35\n",
      "scale: 7.0\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▎                                          | 1/35 [00:00<00:09,  3.61it/s]\u001b[A\n",
      "  6%|██▌                                         | 2/35 [00:00<00:08,  3.79it/s]\u001b[A\n",
      "  9%|███▊                                        | 3/35 [00:00<00:08,  3.86it/s]\u001b[A\n",
      " 11%|█████                                       | 4/35 [00:01<00:08,  3.74it/s]\u001b[A\n",
      " 14%|██████▎                                     | 5/35 [00:01<00:07,  3.81it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:01<00:07,  3.85it/s]\u001b[A\n",
      " 20%|████████▊                                   | 7/35 [00:01<00:07,  3.86it/s]\u001b[A\n",
      " 23%|██████████                                  | 8/35 [00:02<00:07,  3.82it/s]\u001b[A\n",
      " 26%|███████████▎                                | 9/35 [00:02<00:06,  3.85it/s]\u001b[A\n",
      " 29%|████████████▎                              | 10/35 [00:02<00:06,  3.86it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 11/35 [00:02<00:06,  3.87it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:03<00:06,  3.83it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 13/35 [00:03<00:05,  3.83it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 14/35 [00:03<00:05,  3.85it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 15/35 [00:03<00:05,  3.87it/s]\u001b[A\n",
      " 46%|███████████████████▋                       | 16/35 [00:04<00:04,  3.83it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 17/35 [00:04<00:04,  3.83it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:04<00:04,  3.85it/s]\u001b[A\n",
      " 54%|███████████████████████▎                   | 19/35 [00:04<00:04,  3.89it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 20/35 [00:05<00:03,  3.85it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 21/35 [00:05<00:03,  3.84it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 22/35 [00:05<00:03,  3.84it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:05<00:03,  3.86it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 24/35 [00:06<00:02,  3.85it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 25/35 [00:06<00:02,  3.85it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 26/35 [00:06<00:02,  3.85it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▏         | 27/35 [00:07<00:02,  3.84it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:07<00:01,  3.83it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▋       | 29/35 [00:07<00:01,  3.83it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 30/35 [00:07<00:01,  3.83it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████     | 31/35 [00:08<00:01,  3.83it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▎   | 32/35 [00:08<00:00,  3.83it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [00:08<00:00,  3.85it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 34/35 [00:08<00:00,  3.84it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 35/35 [00:09<00:00,  3.84it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:05,  5.14it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  5.72it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  5.91it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.02it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  6.07it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:01<00:04,  5.81it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.90it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.99it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  6.04it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  6.09it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  6.08it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:02<00:02,  6.02it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  6.01it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  6.00it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  6.02it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  6.06it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  6.10it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:03<00:01,  6.07it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  6.07it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  6.09it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  6.07it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  6.07it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  6.08it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:03<00:00,  6.07it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  6.04it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  6.06it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  6.09it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  6.10it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  6.12it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:04<00:00,  6.03it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.46it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.25it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.21it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.20it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  6.18it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:00<00:04,  5.84it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.93it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.98it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  6.04it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  6.06it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  6.09it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:01<00:02,  6.02it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  6.03it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  6.04it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  6.05it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  6.07it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  6.06it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:02<00:01,  6.07it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  6.08it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  6.08it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  6.08it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  6.08it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  6.04it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:03<00:00,  6.02it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  6.03it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  6.02it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  6.02it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  6.04it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  6.04it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:04<00:00,  6.05it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.41it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.23it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.19it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.18it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  6.13it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:00<00:04,  5.83it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.94it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  6.01it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  6.05it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  6.08it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  6.08it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:01<00:02,  6.02it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  6.00it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  6.01it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  6.03it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  6.07it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  6.05it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:02<00:01,  6.02it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  6.01it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  6.01it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  6.02it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  6.06it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  6.05it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:03<00:00,  6.03it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  6.01it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  5.99it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  6.00it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  6.02it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  6.01it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:04<00:00,  6.04it/s]\u001b[A\n",
      "steps:  30%|██████▉                | 120/400 [02:51<06:41,  1.43s/it, loss=0.14]epoch 3/7\n",
      "steps:  45%|█████████▉            | 180/400 [04:12<05:08,  1.40s/it, loss=0.113]epoch 4/7\n",
      "steps:  50%|███████████           | 200/400 [04:39<04:39,  1.40s/it, loss=0.125]generating sample images at step / サンプル画像生成 ステップ: 200\n",
      "prompt: xhendx in a swimsuit  \n",
      "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
      "height: 768\n",
      "width: 512\n",
      "sample_steps: 35\n",
      "scale: 7.0\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▎                                          | 1/35 [00:00<00:09,  3.54it/s]\u001b[A\n",
      "  6%|██▌                                         | 2/35 [00:00<00:08,  3.67it/s]\u001b[A\n",
      "  9%|███▊                                        | 3/35 [00:00<00:08,  3.68it/s]\u001b[A\n",
      " 11%|█████                                       | 4/35 [00:01<00:08,  3.59it/s]\u001b[A\n",
      " 14%|██████▎                                     | 5/35 [00:01<00:08,  3.65it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:01<00:07,  3.69it/s]\u001b[A\n",
      " 20%|████████▊                                   | 7/35 [00:01<00:07,  3.65it/s]\u001b[A\n",
      " 23%|██████████                                  | 8/35 [00:02<00:07,  3.63it/s]\u001b[A\n",
      " 26%|███████████▎                                | 9/35 [00:02<00:07,  3.67it/s]\u001b[A\n",
      " 29%|████████████▎                              | 10/35 [00:02<00:06,  3.70it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 11/35 [00:03<00:06,  3.64it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:03<00:06,  3.66it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 13/35 [00:03<00:06,  3.66it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 14/35 [00:03<00:05,  3.68it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 15/35 [00:04<00:05,  3.66it/s]\u001b[A\n",
      " 46%|███████████████████▋                       | 16/35 [00:04<00:05,  3.66it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 17/35 [00:04<00:04,  3.67it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:04<00:04,  3.66it/s]\u001b[A\n",
      " 54%|███████████████████████▎                   | 19/35 [00:05<00:04,  3.67it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 20/35 [00:05<00:04,  3.65it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 21/35 [00:05<00:03,  3.69it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 22/35 [00:06<00:03,  3.66it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:06<00:03,  3.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 24/35 [00:06<00:03,  3.65it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 25/35 [00:06<00:02,  3.68it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 26/35 [00:07<00:02,  3.68it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▏         | 27/35 [00:07<00:02,  3.66it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:07<00:01,  3.65it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▋       | 29/35 [00:07<00:01,  3.66it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 30/35 [00:08<00:01,  3.66it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████     | 31/35 [00:08<00:01,  3.65it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▎   | 32/35 [00:08<00:00,  3.66it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [00:09<00:00,  3.66it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 34/35 [00:09<00:00,  3.69it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 35/35 [00:09<00:00,  3.66it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.22it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.08it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.08it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.05it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  6.01it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:01<00:04,  5.69it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.78it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.81it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  5.87it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  5.90it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  5.84it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:02<00:03,  5.77it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  5.80it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  5.84it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  5.84it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  5.88it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  5.86it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:03<00:02,  5.81it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  5.81it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  5.83it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  5.87it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  5.85it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  5.87it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:04<00:01,  5.83it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  5.83it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  5.85it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  5.85it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.86it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.26it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.11it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.03it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.03it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  5.96it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:01<00:04,  5.70it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.81it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.86it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  5.90it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  5.91it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  5.82it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:02<00:03,  5.76it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  5.79it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  5.85it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  5.90it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  5.89it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  5.81it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:03<00:02,  5.79it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  5.83it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  5.82it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  5.86it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  5.89it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  5.83it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:04<00:01,  5.83it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  5.84it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  5.89it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  5.89it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  5.83it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.86it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.20it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.04it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.03it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.01it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  5.97it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:01<00:04,  5.74it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.81it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.85it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  5.89it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  5.91it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  5.85it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:02<00:03,  5.78it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  5.82it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  5.85it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  5.89it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  5.92it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  5.86it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:03<00:02,  5.84it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  5.84it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  5.86it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  5.86it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  5.87it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  5.82it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:04<00:01,  5.83it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  5.85it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  5.87it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  5.84it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  5.83it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.86it/s]\u001b[A\n",
      "steps:  60%|█████████████▏        | 240/400 [05:59<03:59,  1.50s/it, loss=0.164]epoch 5/7\n",
      "steps:  75%|█████████████████▎     | 300/400 [07:20<02:26,  1.47s/it, loss=0.13]generating sample images at step / サンプル画像生成 ステップ: 300\n",
      "prompt: xhendx in a swimsuit  \n",
      "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
      "height: 768\n",
      "width: 512\n",
      "sample_steps: 35\n",
      "scale: 7.0\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▎                                          | 1/35 [00:00<00:09,  3.56it/s]\u001b[A\n",
      "  6%|██▌                                         | 2/35 [00:00<00:09,  3.66it/s]\u001b[A\n",
      "  9%|███▊                                        | 3/35 [00:00<00:08,  3.70it/s]\u001b[A\n",
      " 11%|█████                                       | 4/35 [00:01<00:08,  3.61it/s]\u001b[A\n",
      " 14%|██████▎                                     | 5/35 [00:01<00:08,  3.67it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:01<00:07,  3.70it/s]\u001b[A\n",
      " 20%|████████▊                                   | 7/35 [00:01<00:07,  3.67it/s]\u001b[A\n",
      " 23%|██████████                                  | 8/35 [00:02<00:07,  3.68it/s]\u001b[A\n",
      " 26%|███████████▎                                | 9/35 [00:02<00:07,  3.70it/s]\u001b[A\n",
      " 29%|████████████▎                              | 10/35 [00:02<00:06,  3.71it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 11/35 [00:02<00:06,  3.67it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:03<00:06,  3.68it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 13/35 [00:03<00:05,  3.69it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 14/35 [00:03<00:05,  3.69it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 15/35 [00:04<00:05,  3.66it/s]\u001b[A\n",
      " 46%|███████████████████▋                       | 16/35 [00:04<00:05,  3.68it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 17/35 [00:04<00:04,  3.69it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:04<00:04,  3.69it/s]\u001b[A\n",
      " 54%|███████████████████████▎                   | 19/35 [00:05<00:04,  3.68it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 20/35 [00:05<00:04,  3.68it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 21/35 [00:05<00:03,  3.67it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 22/35 [00:05<00:03,  3.68it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:06<00:03,  3.68it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 24/35 [00:06<00:02,  3.69it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 25/35 [00:06<00:02,  3.67it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 26/35 [00:07<00:02,  3.68it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▏         | 27/35 [00:07<00:02,  3.68it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:07<00:01,  3.69it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▋       | 29/35 [00:07<00:01,  3.69it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 30/35 [00:08<00:01,  3.69it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████     | 31/35 [00:08<00:01,  3.67it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▎   | 32/35 [00:08<00:00,  3.68it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [00:08<00:00,  3.68it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 34/35 [00:09<00:00,  3.67it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 35/35 [00:09<00:00,  3.68it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.19it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.06it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.02it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  5.99it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  5.93it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:01<00:04,  5.65it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.76it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.83it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  5.86it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  5.90it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  5.77it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:02<00:03,  5.77it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  5.80it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  5.87it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  5.90it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  5.95it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  5.84it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:03<00:02,  5.82it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  5.84it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  5.89it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  5.93it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  5.92it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  5.88it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:04<00:01,  5.84it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  5.85it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  5.87it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  5.88it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  5.89it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.86it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.24it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.07it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.04it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.04it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  6.02it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:01<00:04,  5.79it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.82it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.87it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  5.90it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  5.92it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  5.94it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:02<00:03,  5.83it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  5.81it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  5.83it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  5.88it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  5.91it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  5.89it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:03<00:02,  5.86it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  5.85it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  5.86it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  5.90it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  5.96it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  5.92it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:04<00:01,  5.87it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  5.86it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  5.87it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  5.88it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.89it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  6.22it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.15it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:04,  6.09it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:04,  6.10it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:04,  6.05it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:01<00:04,  5.71it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  5.81it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  5.87it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  5.90it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:03,  5.91it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:03,  5.88it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:02<00:03,  5.79it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:02<00:02,  5.81it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  5.87it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  5.91it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  5.93it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:02,  5.87it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:03<00:02,  5.82it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:03<00:01,  5.84it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:03<00:01,  5.89it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  5.92it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  5.92it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  5.88it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:04<00:01,  5.84it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:04<00:00,  5.83it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:04<00:00,  5.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:04<00:00,  5.90it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  5.92it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  5.89it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.89it/s]\u001b[A\n",
      "steps:  75%|████████████████▌     | 300/400 [07:47<02:35,  1.56s/it, loss=0.135]epoch 6/7\n",
      "steps:  90%|███████████████████▊  | 360/400 [09:04<01:00,  1.51s/it, loss=0.134]epoch 7/7\n",
      "steps: 100%|██████████████████████| 400/400 [09:50<00:00,  1.48s/it, loss=0.132]generating sample images at step / サンプル画像生成 ステップ: 400\n",
      "prompt: xhendx in a swimsuit  \n",
      "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
      "height: 768\n",
      "width: 512\n",
      "sample_steps: 35\n",
      "scale: 7.0\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▎                                          | 1/35 [00:00<00:08,  4.11it/s]\u001b[A\n",
      "  6%|██▌                                         | 2/35 [00:00<00:07,  4.24it/s]\u001b[A\n",
      "  9%|███▊                                        | 3/35 [00:00<00:07,  4.29it/s]\u001b[A\n",
      " 11%|█████                                       | 4/35 [00:00<00:07,  4.26it/s]\u001b[A\n",
      " 14%|██████▎                                     | 5/35 [00:01<00:06,  4.29it/s]\u001b[A\n",
      " 17%|███████▌                                    | 6/35 [00:01<00:06,  4.31it/s]\u001b[A\n",
      " 20%|████████▊                                   | 7/35 [00:01<00:06,  4.32it/s]\u001b[A\n",
      " 23%|██████████                                  | 8/35 [00:01<00:06,  4.33it/s]\u001b[A\n",
      " 26%|███████████▎                                | 9/35 [00:02<00:06,  4.33it/s]\u001b[A\n",
      " 29%|████████████▎                              | 10/35 [00:02<00:05,  4.33it/s]\u001b[A\n",
      " 31%|█████████████▌                             | 11/35 [00:02<00:05,  4.33it/s]\u001b[A\n",
      " 34%|██████████████▋                            | 12/35 [00:02<00:05,  4.32it/s]\u001b[A\n",
      " 37%|███████████████▉                           | 13/35 [00:03<00:05,  4.32it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 14/35 [00:03<00:04,  4.33it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 15/35 [00:03<00:04,  4.33it/s]\u001b[A\n",
      " 46%|███████████████████▋                       | 16/35 [00:03<00:04,  4.33it/s]\u001b[A\n",
      " 49%|████████████████████▉                      | 17/35 [00:03<00:04,  4.32it/s]\u001b[A\n",
      " 51%|██████████████████████                     | 18/35 [00:04<00:03,  4.33it/s]\u001b[A\n",
      " 54%|███████████████████████▎                   | 19/35 [00:04<00:03,  4.33it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 20/35 [00:04<00:03,  4.33it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 21/35 [00:04<00:03,  4.33it/s]\u001b[A\n",
      " 63%|███████████████████████████                | 22/35 [00:05<00:03,  4.32it/s]\u001b[A\n",
      " 66%|████████████████████████████▎              | 23/35 [00:05<00:02,  4.34it/s]\u001b[A\n",
      " 69%|█████████████████████████████▍             | 24/35 [00:05<00:02,  4.33it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 25/35 [00:05<00:02,  4.34it/s]\u001b[A\n",
      " 74%|███████████████████████████████▉           | 26/35 [00:06<00:02,  4.34it/s]\u001b[A\n",
      " 77%|█████████████████████████████████▏         | 27/35 [00:06<00:01,  4.33it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 28/35 [00:06<00:01,  4.33it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▋       | 29/35 [00:06<00:01,  4.34it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 30/35 [00:06<00:01,  4.33it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████     | 31/35 [00:07<00:00,  4.33it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████▎   | 32/35 [00:07<00:00,  4.32it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [00:07<00:00,  4.33it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 34/35 [00:07<00:00,  4.34it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 35/35 [00:08<00:00,  4.32it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  7.13it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:04,  6.97it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:03,  6.93it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:03,  6.91it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:03,  6.89it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:00<00:03,  6.85it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  6.82it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  6.84it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  6.85it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:02,  6.84it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:02,  6.84it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:01<00:02,  6.84it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:01<00:02,  6.85it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  6.85it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  6.84it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  6.83it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:01,  6.84it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:02<00:01,  6.84it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:02<00:01,  6.82it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:02<00:01,  6.82it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  6.83it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  6.84it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  6.85it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:03<00:00,  6.84it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:03<00:00,  6.83it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:03<00:00,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:03<00:00,  6.84it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  6.83it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  6.83it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:04<00:00,  6.85it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:03,  7.26it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:03,  7.02it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:03,  6.96it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:03,  6.92it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:03,  6.88it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:00<00:03,  6.86it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  6.83it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  6.83it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  6.84it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:02,  6.83it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:02,  6.84it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:01<00:02,  6.83it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:01<00:02,  6.83it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  6.82it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  6.83it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  6.85it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:01,  6.85it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:02<00:01,  6.83it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:02<00:01,  6.84it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:02<00:01,  6.84it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  6.85it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  6.85it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  6.82it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:03<00:00,  6.83it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:03<00:00,  6.84it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:03<00:00,  6.83it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:03<00:00,  6.82it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  6.83it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  6.84it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:04<00:00,  6.85it/s]\u001b[A\n",
      "prompt: xhendx in a swimsuit\n",
      "negative_prompt: None\n",
      "height: 512\n",
      "width: 512\n",
      "sample_steps: 30\n",
      "scale: 7.5\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:00<00:04,  7.21it/s]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:00<00:03,  7.01it/s]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:00<00:03,  6.95it/s]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:00<00:03,  6.90it/s]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:00<00:03,  6.90it/s]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:00<00:03,  6.88it/s]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:01<00:03,  6.84it/s]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:01<00:03,  6.86it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:01<00:03,  6.84it/s]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:01<00:02,  6.85it/s]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:01<00:02,  6.86it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:01<00:02,  6.85it/s]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:01<00:02,  6.83it/s]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:02<00:02,  6.82it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:02<00:02,  6.84it/s]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:02<00:02,  6.84it/s]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:02<00:01,  6.86it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:02<00:01,  6.84it/s]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:02<00:01,  6.84it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:02<00:01,  6.83it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:03<00:01,  6.84it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:03<00:01,  6.84it/s]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:03<00:01,  6.83it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:03<00:00,  6.83it/s]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:03<00:00,  6.84it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:03<00:00,  6.84it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:03<00:00,  6.83it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:04<00:00,  6.82it/s]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:04<00:00,  6.83it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:04<00:00,  6.85it/s]\u001b[A\n",
      "steps: 100%|██████████████████████| 400/400 [10:13<00:00,  1.53s/it, loss=0.132]save trained model as StableDiffusion checkpoint to /home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/output/Hendricks4.ckpt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/train_db.py\", line 425, in <module>\n",
      "    train(args)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/train_db.py\", line 387, in train\n",
      "    train_util.save_sd_model_on_train_end(\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/library/train_util.py\", line 2952, in save_sd_model_on_train_end\n",
      "    huggingface_util.upload(args, ckpt_file, \"/\" + ckpt_name, force_sync_upload=True)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/library/huggingface_util.py\", line 36, in upload\n",
      "    api.create_repo(repo_id=repo_id, repo_type=repo_type, private=private)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\", line 120, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/hf_api.py\", line 2076, in create_repo\n",
      "    headers = self._build_hf_headers(token=token, is_write_action=True)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/hf_api.py\", line 4205, in _build_hf_headers\n",
      "    return build_hf_headers(\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\", line 120, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_headers.py\", line 118, in build_hf_headers\n",
      "    _validate_token_to_send(token_to_send, is_write_action=is_write_action)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/huggingface_hub/utils/_headers.py\", line 168, in _validate_token_to_send\n",
      "    raise ValueError(\n",
      "ValueError: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.\n",
      "steps: 100%|██████████████████████| 400/400 [10:17<00:00,  1.54s/it, loss=0.132]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 1104, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/accelerate/commands/launch.py\", line 567, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/home/studio-lab-user/.conda/envs/default/bin/python3.9', 'train_db.py', '--sample_prompts=/home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/config/sample_prompt.txt', '--dataset_config=/home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/config/dataset_config.toml', '--config_file=/home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/config/config_file.toml']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "#@title ## 5.5. Start Training\n",
    "\n",
    "#@markdown Check your config here if you want to edit something: \n",
    "#@markdown - `sample_prompt` : /content/dreambooth/config/sample_prompt.txt\n",
    "#@markdown - `config_file` : /content/dreambooth/config/config_file.toml\n",
    "#@markdown - `dataset_config` : /content/dreambooth/config/dataset_config.toml\n",
    "\n",
    "#@markdown Generated sample can be seen here: /content/dreambooth/output/sample\n",
    "\n",
    "#@markdown You can import config from another session if you want.\n",
    "sample_prompt = os.path.join(dreambooth_training_dir,\"config/sample_prompt.txt\") #@param {type:'string'}\n",
    "config_file = os.path.join(dreambooth_training_dir,\"config/config_file.toml\") #@param {type:'string'}\n",
    "dataset_config = os.path.join(dreambooth_training_dir,\"config/dataset_config.toml\") #@param {type:'string'}\n",
    "\n",
    "accelerate_conf = {\n",
    "    \"config_file\" : accelerate_config,\n",
    "    \"num_cpu_threads_per_process\" : 1,\n",
    "}\n",
    "\n",
    "train_conf = {\n",
    "    \"sample_prompts\" : sample_prompt,\n",
    "    \"dataset_config\" : dataset_config,\n",
    "    \"config_file\" : config_file\n",
    "}\n",
    "\n",
    "def train(config):\n",
    "    args = \"\"\n",
    "    for k, v in config.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            args += f'\"{v}\" '\n",
    "        elif isinstance(v, str):\n",
    "            args += f'--{k}=\"{v}\" '\n",
    "        elif isinstance(v, bool) and v:\n",
    "            args += f\"--{k} \"\n",
    "        elif isinstance(v, float) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "        elif isinstance(v, int) and not isinstance(v, bool):\n",
    "            args += f\"--{k}={v} \"\n",
    "\n",
    "    return args\n",
    "\n",
    "accelerate_args = train(accelerate_conf)\n",
    "train_args = train(train_conf)\n",
    "final_args = f\"accelerate launch {accelerate_args} train_db.py {train_args}\"\n",
    "os.chdir(repo_dir)\n",
    "!{final_args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f937f88d-819a-4e35-bc36-353198d18048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:26:03.325452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-01 16:26:05.066757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "load StableDiffusion checkpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/gen_img_diffusers.py\", line 3262, in <module>\n",
      "    main(args)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/gen_img_diffusers.py\", line 2110, in main\n",
      "    text_encoder, vae, unet = model_util.load_models_from_stable_diffusion_checkpoint(args.v2, args.ckpt)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/library/model_util.py\", line 850, in load_models_from_stable_diffusion_checkpoint\n",
      "    _, state_dict = load_checkpoint_with_text_encoder_conversion(ckpt_path, device)\n",
      "  File \"/home/studio-lab-user/sagemaker-studiolab-notebooks/kohya-trainer/library/model_util.py\", line 827, in load_checkpoint_with_text_encoder_conversion\n",
      "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 809, in load\n",
      "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 1172, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 1142, in persistent_load\n",
      "    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 1116, in load_tensor\n",
      "    wrap_storage=restore_location(storage, location),\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 1083, in restore_location\n",
      "    return default_restore_location(storage, map_location)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 217, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 182, in _cuda_deserialize\n",
      "    device = validate_cuda_device(location)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/serialization.py\", line 166, in validate_cuda_device\n",
      "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
      "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "# @title ## 6.2. Inference\n",
    "v2 = False  # @param {type:\"boolean\"}\n",
    "v_parameterization = False  # @param {type:\"boolean\"}\n",
    "prompt = \"RAW photo, xhendx in a bikini, high detailed skin, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3\"  # @param {type: \"string\"}\n",
    "negative = \"(weird eyes, disfigured eyes, looking different direction:1.3), cgi, 3d, render, mutated hands, mutated fingers, deformed, distorted, disfigured, poorly drawn, bad anatomy, bad quality, worst quality\"  # @param {type: \"string\"}\n",
    "model = os.path.join(dreambooth_output_dir,'Hen1-fp16-pruned.ckpt')  # @param {type: \"string\"}\n",
    "vae = os.path.join(vae_dir,'vae-ft-mse-840000-ema-pruned.ckpt')  # @param {type: \"string\"}\n",
    "outdir = inference_dir  # @param {type: \"string\"}\n",
    "scale = 7  # @param {type: \"slider\", min: 1, max: 40}\n",
    "sampler = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
    "steps = 35  # @param {type: \"slider\", min: 1, max: 100}\n",
    "precision = \"fp16\"  # @param [\"fp16\", \"bf16\"] {allow-input: false}\n",
    "width = 512  # @param {type: \"integer\"}\n",
    "height = 768  # @param {type: \"integer\"}\n",
    "images_per_prompt = 12  # @param {type: \"integer\"}\n",
    "batch_size = 1  # @param {type: \"integer\"}\n",
    "clip_skip = 1  # @param {type: \"slider\", min: 1, max: 40}\n",
    "seed = -1  # @param {type: \"integer\"}\n",
    "\n",
    "final_prompt = f\"{prompt} --n {negative}\"\n",
    "\n",
    "config = {\n",
    "    \"v2\": v2,\n",
    "    \"v_parameterization\": v_parameterization,\n",
    "    \"ckpt\": model,\n",
    "    \"outdir\": outdir,\n",
    "    \"xformers\": True,\n",
    "    \"vae\": vae if vae else None,\n",
    "    \"fp16\": True,\n",
    "    \"W\": width,\n",
    "    \"H\": height,\n",
    "    \"seed\": seed if seed > 0 else None,\n",
    "    \"scale\": scale,\n",
    "    \"sampler\": sampler,\n",
    "    \"steps\": steps,\n",
    "    \"max_embeddings_multiples\": 3,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"images_per_prompt\": images_per_prompt,\n",
    "    \"clip_skip\": clip_skip if not v2 else None,\n",
    "    \"prompt\": final_prompt,\n",
    "}\n",
    "\n",
    "args = \"\"\n",
    "for k, v in config.items():\n",
    "    if isinstance(v, str):\n",
    "        args += f'--{k}=\"{v}\" '\n",
    "    if isinstance(v, bool) and v:\n",
    "        args += f\"--{k} \"\n",
    "    if isinstance(v, float) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "    if isinstance(v, int) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "\n",
    "final_args = f\"python gen_img_diffusers.py {args}\"\n",
    "\n",
    "os.chdir(repo_dir)\n",
    "!{final_args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec053eed-bc75-4fce-a6b4-1362f5e86a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-01 15:52:46--  https://raw.githubusercontent.com/lopho/stable-diffusion-prune/main/prune.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4374 (4.3K) [text/plain]\n",
      "Saving to: 'prune.py'\n",
      "\n",
      "prune.py            100%[===================>]   4.27K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-06-01 15:52:46 (43.5 MB/s) - 'prune.py' saved [4374/4374]\n",
      "\n",
      "Loading model from /home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/output/Hen1.ckpt\n",
      "Applying option fp16\n",
      "Saving pruned model to /home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/output/Hen1-fp16-pruned.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#@title ## 7.2. Model Pruner\n",
    "\n",
    "os.chdir(tools_dir)\n",
    "\n",
    "if not os.path.exists('prune.py'):\n",
    "    !wget https://raw.githubusercontent.com/lopho/stable-diffusion-prune/main/prune.py\n",
    "\n",
    "#@markdown Convert to Float16\n",
    "fp16 = True #@param {'type':'boolean'}\n",
    "#@markdown Use EMA for weights\n",
    "ema = False #@param {'type':'boolean'}\n",
    "#@markdown Strip CLIP weights\n",
    "no_clip = False #@param {'type':'boolean'}\n",
    "#@markdown Strip VAE weights\n",
    "no_vae = False #@param {'type':'boolean'}\n",
    "#@markdown Strip depth model weights\n",
    "no_depth = False #@param {'type':'boolean'}\n",
    "#@markdown Strip UNet weights\n",
    "no_unet = False #@param {'type':'boolean'}\n",
    "\n",
    "model_path = \"/home/studio-lab-user/sagemaker-studiolab-notebooks/dreambooth/output/Hen1.ckpt\" #@param {'type' : 'string'}\n",
    "\n",
    "config = {\n",
    "    \"fp16\": fp16,\n",
    "    \"ema\": ema,\n",
    "    \"no_clip\": no_clip,\n",
    "    \"no_vae\": no_vae,\n",
    "    \"no_depth\": no_depth,\n",
    "    \"no_unet\": no_unet,\n",
    "}\n",
    "\n",
    "suffixes = {\n",
    "    \"fp16\": \"-fp16\",\n",
    "    \"ema\": \"-ema\",\n",
    "    \"no_clip\": \"-no-clip\",\n",
    "    \"no_vae\": \"-no-vae\",\n",
    "    \"no_depth\": \"-no-depth\",\n",
    "    \"no_unet\": \"-no-unet\",\n",
    "}\n",
    "\n",
    "print(f\"Loading model from {model_path}\")\n",
    "\n",
    "dir_name = os.path.dirname(model_path)\n",
    "base_name = os.path.basename(model_path)\n",
    "output_name = base_name.split('.')[0]\n",
    "\n",
    "for option, suffix in suffixes.items():\n",
    "    if config[option]:\n",
    "        print(f\"Applying option {option}\")\n",
    "        output_name += suffix\n",
    "        \n",
    "output_name += '-pruned'\n",
    "output_path = os.path.join(dir_name, output_name + ('.ckpt' if model_path.endswith(\".ckpt\") else \".safetensors\"))\n",
    "\n",
    "args = \"\"\n",
    "for k, v in config.items():\n",
    "    if k.startswith(\"_\"):\n",
    "        args += f'\"{v}\" '\n",
    "    elif isinstance(v, str):\n",
    "        args += f'--{k}=\"{v}\" '\n",
    "    elif isinstance(v, bool) and v:\n",
    "        args += f\"--{k} \"\n",
    "    elif isinstance(v, float) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "    elif isinstance(v, int) and not isinstance(v, bool):\n",
    "        args += f\"--{k}={v} \"\n",
    "\n",
    "final_args = f\"python3 prune.py {model_path} {output_path} {args}\"\n",
    "!{final_args}\n",
    "\n",
    "print(f\"Saving pruned model to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8a51b3-8edb-441e-9e51-fcfee60905a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/studio-lab-user/.cache/huggingface/token\n",
      "Login successful\n",
      "Model repo 'xxthekingxx/myHendricks2' exists, skipping create repo\n",
      "Model repo 'xxthekingxx/myHendricks2' link: https://huggingface.co/xxthekingxx/myHendricks2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title ## 7.1. Upload Config\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
    "\n",
    "\n",
    "# @markdown Login to Huggingface Hub\n",
    "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
    "write_token = \"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\"  # @param {type:\"string\"}\n",
    "# @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
    "orgs_name = \"\"  # @param{type:\"string\"}\n",
    "# @markdown If your model/dataset repo does not exist, it will automatically create it.\n",
    "model_name = \"myHendricks2\"  # @param{type:\"string\"}\n",
    "dataset_name = \"\"  # @param{type:\"string\"}\n",
    "make_private = True  # @param{type:\"boolean\"}\n",
    "\n",
    "def authenticate(write_token):\n",
    "    login(write_token, add_to_git_credential=True)\n",
    "    api = HfApi()\n",
    "    return api.whoami(write_token), api\n",
    "\n",
    "\n",
    "def create_repo(api, user, orgs_name, repo_name, repo_type, make_private=False):\n",
    "    global model_repo\n",
    "    global datasets_repo\n",
    "    \n",
    "    if orgs_name == \"\":\n",
    "        repo_id = user[\"name\"] + \"/\" + repo_name.strip()\n",
    "    else:\n",
    "        repo_id = orgs_name + \"/\" + repo_name.strip()\n",
    "\n",
    "    try:\n",
    "        validate_repo_id(repo_id)\n",
    "        api.create_repo(repo_id=repo_id, repo_type=repo_type, private=make_private)\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' didn't exist, creating repo\")\n",
    "    except HfHubHTTPError as e:\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' exists, skipping create repo\")\n",
    "    \n",
    "    if repo_type == \"model\":\n",
    "        model_repo = repo_id\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
    "    else:\n",
    "        datasets_repo = repo_id\n",
    "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/datasets/{repo_id}\\n\")\n",
    "\n",
    "user, api = authenticate(write_token)\n",
    "\n",
    "if model_name:\n",
    "    create_repo(api, user, orgs_name, model_name, \"model\", make_private)\n",
    "if dataset_name:\n",
    "    create_repo(api, user, orgs_name, dataset_name, \"dataset\", make_private)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38929646-2133-4704-a8c9-dbc6b1b45f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Hen1.ckpt to https://huggingface.co/xxthekingxx/myHendricks2\n",
      "Please wait...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7440fcfbd847f1b33cf98f3a45638a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Hen1.ckpt:   0%|          | 0.00/2.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59807536ab348dc8e4f15b982333047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload success, located at https://huggingface.co/xxthekingxx/myHendricks2/blob/main/Hen1.ckpt\n",
      "\n",
      "Uploading Hen1_config to https://huggingface.co/xxthekingxx/myHendricks2\n",
      "Please wait...\n",
      "Upload success, located at https://huggingface.co/xxthekingxx/myHendricks2/tree/main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title ### 8.2.1. Upload Model\n",
    "from huggingface_hub import HfApi\n",
    "from pathlib import Path\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# @markdown This will be uploaded to model repo\n",
    "model_path = os.path.join(dreambooth_output_dir,\"Hen1.ckpt\")  # @param {type :\"string\"}\n",
    "path_in_repo = \"\"  # @param {type :\"string\"}\n",
    "# @markdown Now you can save your config file for future use\n",
    "config_path = dreambooth_config_dir  # @param {type :\"string\"}\n",
    "# @markdown Other Information\n",
    "commit_message = \"uploading model\"  # @param {type :\"string\"}\n",
    "\n",
    "if not commit_message:\n",
    "    commit_message = \"feat: upload \" + project_name.value + \" checkpoint\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    vae_exists = os.path.exists(os.path.join(model_path, \"vae\"))\n",
    "    unet_exists = os.path.exists(os.path.join(model_path, \"unet\"))\n",
    "    text_encoder_exists = os.path.exists(os.path.join(model_path, \"text_encoder\"))\n",
    "\n",
    "\n",
    "def upload_model(model_paths, is_folder: bool, is_config: bool):\n",
    "    path_obj = Path(model_paths)\n",
    "    trained_model = path_obj.parts[-1]\n",
    "\n",
    "    if path_in_repo:\n",
    "        trained_model = path_in_repo\n",
    "\n",
    "    if is_config:\n",
    "        if path_in_repo:\n",
    "            trained_model = f\"{path_in_repo}_config\"\n",
    "        else:\n",
    "            trained_model = f\"{project_name.value}_config\"\n",
    "\n",
    "    if is_folder == True:\n",
    "        print(f\"Uploading {trained_model} to https://huggingface.co/\" + model_repo)\n",
    "        print(f\"Please wait...\")\n",
    "\n",
    "        if vae_exists and unet_exists and text_encoder_exists:\n",
    "            api.upload_folder(\n",
    "                folder_path=model_paths,\n",
    "                repo_id=model_repo,\n",
    "                commit_message=commit_message,\n",
    "                ignore_patterns=\".ipynb_checkpoints\",\n",
    "            )\n",
    "        else:\n",
    "            api.upload_folder(\n",
    "                folder_path=model_paths,\n",
    "                path_in_repo=trained_model,\n",
    "                repo_id=model_repo,\n",
    "                commit_message=commit_message,\n",
    "                ignore_patterns=\".ipynb_checkpoints\",\n",
    "            )\n",
    "        print(\n",
    "            f\"Upload success, located at https://huggingface.co/\"\n",
    "            + model_repo\n",
    "            + \"/tree/main\\n\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Uploading {trained_model} to https://huggingface.co/\" + model_repo)\n",
    "        print(f\"Please wait...\")\n",
    "\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=model_paths,\n",
    "            path_in_repo=trained_model,\n",
    "            repo_id=model_repo,\n",
    "            commit_message=commit_message,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Upload success, located at https://huggingface.co/\"\n",
    "            + model_repo\n",
    "            + \"/blob/main/\"\n",
    "            + trained_model\n",
    "            + \"\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "def upload():\n",
    "    if model_path.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
    "        upload_model(model_path, False, False)\n",
    "    else:\n",
    "        upload_model(model_path, True, False)\n",
    "\n",
    "    if config_path:\n",
    "        upload_model(config_path, True, True)\n",
    "\n",
    "\n",
    "upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc949e-66a8-4ea1-938c-4a6f2b53cd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
